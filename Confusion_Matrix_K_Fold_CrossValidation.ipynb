{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment #2 - Ruben",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubencg195/Pytorch-Tutorials/blob/master/Confusion_Matrix_K_Fold_CrossValidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "diFMA15hpsvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ]
    },
    {
      "metadata": {
        "id": "aNR7TM7KBFpO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Console Parameters\n",
        "import sys \n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "#Machine Learning\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import neighbors, datasets\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.metrics import accuracy_score,  precision_recall_curve, average_precision_score, mean_squared_error\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.utils.fixes import signature\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "  \n",
        "#Utils - Math and Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randrange\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I-3POnjDwA8B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "debug              = False\n",
        "varianceThreshold  = 0.0005\n",
        "# varianceThreshold  = 0.001\n",
        "K                  = 17\n",
        "FoldSize           = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4PnnDDGbwDmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loadDataset(filename):\n",
        "  print(\"Loading Dataset (Process 1 of 7)\")\n",
        "  df = pd.read_csv( filename ,sep='\\t', header=None)\n",
        "  data = np.array( df.as_matrix() )\n",
        "  if debug:\n",
        "    print(df.head())\n",
        "    print(\"\\nRaw_Data_Shape\\t{}\\tNumber_of_Features\\t{}\".format(df.shape, len(df)) )\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ryVkgVkdwFv_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def OrderByVariance(data):\n",
        "  print(\"Order and Filter By Variance (Process 2 of 7)\")\n",
        "  #Take Out Labels from data\n",
        "  features_without_label = data[: , :-1]\n",
        "  #Separate Labels in a different array\n",
        "  labels                 = data[: , -1]\n",
        "  #Get Variance per Column\n",
        "  variance               = np.var(features_without_label,0)\n",
        "  #Sort Variance per Column From Bigger To Smaller\n",
        "  new_index_by_var_sort  = np.argsort(variance)[::-1]                \n",
        "  selector               = VarianceThreshold(varianceThreshold) \n",
        "  #Filter Columns, Delete all columns with variance lesser than threshhold\n",
        "  data                   = selector.fit_transform(data[:,new_index_by_var_sort])\n",
        "  #append again the labels\n",
        "  data                   = np.c_[data, labels ]\n",
        "  if debug:\n",
        "    print(\"\\n\\nfeatures_without_label\\t{}\\tlabels\\t{}\".format(features_without_label.shape, labels.shape))\n",
        "    print(\"\\n\\nTable of Variance Per Feature\\n\\n\",       pd.DataFrame([variance], index=[\"Variance\"]))\n",
        "    print(\"\\nNew Order Based on Features with Higher Variance to lower\\n\",\n",
        "    pd.DataFrame([\n",
        "        variance[new_index_by_var_sort]\n",
        "    ], columns=new_index_by_var_sort,\n",
        "    index=[\"Variance\"]))\n",
        "    print(\"\\nVariance Filtered Data (with Label Col.) \\n\", pd.DataFrame(data).head())\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYHJM_A_yDhg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def CrossValidationSplit(dataset, folds=10):\n",
        "  # Divide the dataset D pseudo-randomly into V folds\n",
        "  dataset_split = list()\n",
        "  dataset_copy = list(dataset)\n",
        "  fold_size = int(len(dataset) / folds)\n",
        "  for i in range(folds):\n",
        "    fold = list()\n",
        "    while len(fold) < fold_size:\n",
        "      index = randrange(len(dataset_copy))\n",
        "      fold.append(dataset_copy.pop(index))\n",
        "    dataset_split.append(fold)\n",
        "  return dataset_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJ6lO5HnyG30",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def EqualyDistributePositiveAndNegativeAndSplit(data):\n",
        "  print(\"Cross Validation Split (Process 3 of 7)\")\n",
        "  #Separate Positives & Negatives\n",
        "  p_indexes      = (data[:,-1] == 1 )\n",
        "  n_indexes      = (data[:,-1] == 0 )\n",
        "  data_positives = data[p_indexes , :]\n",
        "  data_negatives = data[n_indexes,  :]\n",
        "  #Cross Validation to positives and negatives\n",
        "  p_folds         = np.array(CrossValidationSplit(data_positives, FoldSize))\n",
        "  n_folds         = np.array(CrossValidationSplit(data_negatives, FoldSize))\n",
        "  n_rows_per_fold = p_folds.shape[1] + n_folds.shape[1]\n",
        "  #Empty Array To Store Folds\n",
        "  folds = np.array([]).reshape(0,n_rows_per_fold, data.shape[1])\n",
        "  #Join in equaly distributed way, positives and negatives\n",
        "  for i in range(FoldSize):\n",
        "    f = np.r_[p_folds[i] , n_folds[i] ] \n",
        "    #Shuffle features\n",
        "    np.random.shuffle(f)\n",
        "    folds = np.append( folds ,[f], axis=0 )\n",
        "  if debug:\n",
        "    print(\"\\nPositives\\t{}\".format(    data_positives.shape) )\n",
        "    print(\"Negatives\\t{}\".format(data_negatives.shape))\n",
        "    print(\"Folds_Positives\\t{}\\nFolds_Negatives\\t{}\\nFolds_Shuffled_and_Joined\\t{}\".format(p_folds.shape, n_folds.shape, folds.shape))\n",
        "  return folds, n_rows_per_fold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_pIrFtkyJ2V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def CrossValidation(folds, data, K):\n",
        "  print(\"Cross Validation-Selecting Best Model (Process 4 of 7)\")\n",
        "  bestPerFold = np.array([])\n",
        "  bestValues  = {\n",
        "      \"fSelectedIndexes\": np.array([0], dtype=int),  \n",
        "      \"Precision\" :       0.0,\n",
        "      \"Accuracy\"  :       0.0,\n",
        "      \"mse\"       :       9999.0\n",
        "  }\n",
        "  if(debug):\n",
        "    print(\"\\n\\nStarting Cross Validation\\n\\n\")\n",
        "  for i, f in enumerate(folds): \n",
        "    dataset_copy         =  list(folds)\n",
        "    #Define set T as the I-th fold of the dataset D\n",
        "    test_fold            =  dataset_copy.pop(i)  \n",
        "    #Define set L as the dataset D without the I-th fold\n",
        "    dataset_without_fold =  dataset_copy       \n",
        "    dataset_without_fold =  np.array(dataset_without_fold).reshape((-1, data.shape[1]))\n",
        "    #Iterate through all the features to select only the bests\n",
        "    for feature_index in range(1, dataset_without_fold.shape[1] - 1) : \n",
        "      #Exclude the last column because is labels\n",
        "      #Append the next feature index to be tested\n",
        "      bestEpisodeValues = {\n",
        "        \"fSelectedIndexes\": np.append( bestValues[\"fSelectedIndexes\"], feature_index ),   \n",
        "        \"Precision\" :       0.0,\n",
        "        \"Accuracy\"  :       0.0,\n",
        "        \"mse\"       :       9999.0\n",
        "      }\n",
        "      #Create Dataset Only With The Testing Feature Indexes\n",
        "      X = dataset_without_fold[:, bestEpisodeValues[\"fSelectedIndexes\"] ]\n",
        "      y = dataset_without_fold[:, -1].reshape(-1)\n",
        "      test_data       = test_fold[:, bestEpisodeValues[\"fSelectedIndexes\"] ]\n",
        "      test_true_label = test_fold[:, -1].reshape(-1)\n",
        "      #Iterate through all the possible K values in every Feature Test and every Fold Test\n",
        "      for k in range(3, K, 2):\n",
        "        clf                           = KNeighborsClassifier(n_neighbors=k)\n",
        "        training_acc                  = clf.fit(X, y).score(X, y)\n",
        "        # predictions                   = clf.predict(test_data)\n",
        "        predictions                   = clf.predict_proba(test_data)\n",
        "        accuracy                      = accuracy_score(test_true_label, predictions)\n",
        "        precision, recall, thresholds = precision_recall_curve( test_true_label, predictions)\n",
        "        ave_precision                 = average_precision_score(test_true_label, predictions)\n",
        "        mse                           = mean_squared_error(test_true_label, predictions)\n",
        "        #If the accuracy for this model is better than the previous, replace\n",
        "        if( accuracy > bestEpisodeValues[\"Accuracy\"] ):\n",
        "          bestEpisodeValues[\"k\"]                = k \n",
        "          bestEpisodeValues[\"featureIndex\"]     = feature_index \n",
        "          bestEpisodeValues[\"testFoldIndex\"]    = i\n",
        "          bestEpisodeValues[\"Precision\"]        = ave_precision\n",
        "          bestEpisodeValues[\"Accuracy\"]         = accuracy \n",
        "          bestEpisodeValues[\"Recall\"]           = recall\n",
        "          bestEpisodeValues[\"mse\"]              = mse \n",
        "      #If the model selected for this testing set of features is better than the previous\n",
        "      #Replace K value and append new feature index, in the list of best features\n",
        "      if( bestEpisodeValues[\"Accuracy\"] > bestValues[\"Accuracy\"] ):\n",
        "        bestValues[\"k\"]                = bestEpisodeValues[\"k\"]  \n",
        "        if bestEpisodeValues[\"featureIndex\"] not in bestValues[\"fSelectedIndexes\"]:\n",
        "          bestValues[\"fSelectedIndexes\"] =   np.append(bestValues[\"fSelectedIndexes\"], bestEpisodeValues[\"featureIndex\"] ) \n",
        "        bestValues[\"featureIndex\"]     = bestEpisodeValues[\"featureIndex\"] \n",
        "        bestValues[\"testFoldIndex\"]    = bestEpisodeValues[\"testFoldIndex\"] \n",
        "        bestValues[\"Precision\"]        = bestEpisodeValues[\"Precision\"] \n",
        "        bestValues[\"Accuracy\"]         = bestEpisodeValues[\"Accuracy\"] \n",
        "        bestValues[\"Recall\"]           = bestEpisodeValues[\"Recall\"] \n",
        "        bestValues[\"mse\"]              = bestEpisodeValues[\"mse\"] \n",
        "    if(debug):\n",
        "      print(\"FoldCounter\\t{}\\tSelected_K\\t{}\\tSelected_Features\\t{}\\tModel_Acc\\t{:.5f}\".format(\n",
        "          i,\n",
        "          bestValues[\"k\"] , \n",
        "          bestValues[\"fSelectedIndexes\"] , \n",
        "          bestValues[\"Accuracy\"]\n",
        "      ))\n",
        "    #Save the best one per fold, for debugging purposes\n",
        "    bestPerFold = np.append(bestPerFold, bestValues.copy)  \n",
        "  return bestValues"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIKlAq4xyRds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def PlotCurves(folds, bestModel, data ):\n",
        "  print(\"Ploting Precision-Recall & ROC Curve (Process 6 of 7)\")\n",
        "  #Global Containers\n",
        "  ave_acc = np.array([])\n",
        "  ave_pre = np.array([]).reshape(0,3)\n",
        "  ave_rec = np.array([]).reshape(0,3)\n",
        "  ave_roc = np.array([]).reshape(0,3)\n",
        "  ave_mse = np.array([])\n",
        "  tot_ave_pre = np.array([])\n",
        "  ave_metrics = np.array([]).reshape(0,4)\n",
        "  #GraphPointers\n",
        "  pre_rec_fig = plt.figure()\n",
        "  roc_fig     = plt.figure()\n",
        "  pre_rec_ax = pre_rec_fig.gca()\n",
        "  roc_ax     = roc_fig.gca()\n",
        "  #Iterate all Folds\n",
        "  for i, f in enumerate(folds):\n",
        "    #Prepare Data as in CV function, but this time with the Selected Best Features\n",
        "    dataset_copy         =  list(folds)\n",
        "    test_fold            =  dataset_copy.pop(i)  \n",
        "    dataset_without_fold =  dataset_copy         \n",
        "    dataset_without_fold =  np.array(dataset_without_fold).reshape((-1, data.shape[1]))\n",
        "    X                    = dataset_without_fold[:, bestModel[\"fSelectedIndexes\"] ]\n",
        "    y                    = dataset_without_fold[:, -1].reshape(-1)\n",
        "    test_data            = test_fold[:, bestModel[\"fSelectedIndexes\"] ]\n",
        "    test_true_label      = test_fold[:, -1].reshape(-1)\n",
        "    #Train Per Fold with Best Features to get Average Scores\n",
        "    clf                           = KNeighborsClassifier(n_neighbors=bestModel[\"k\"])\n",
        "    clf.fit(X, y) \n",
        "    predictions                   = clf.predict(test_data)\n",
        "    #Scores\n",
        "    accuracy                      = accuracy_score(test_true_label, predictions)\n",
        "    precision, recall, thresholds = precision_recall_curve( test_true_label, predictions)\n",
        "    fpr, tpr, thresholds          = roc_curve( test_true_label, predictions)\n",
        "    roc_auc                       = auc(fpr, tpr)\n",
        "    ave_precision                 = average_precision_score(test_true_label, predictions)\n",
        "    mse                           = mean_squared_error(test_true_label, predictions)\n",
        "    tn, fp, fn, tp                = confusion_matrix(test_true_label, predictions).ravel()\n",
        "    #Plots Per Folds\n",
        "    pre_rec_ax.plot(precision, recall, lw=1, alpha=0.3,\n",
        "              label='Precision-Recall fold %d (Ave. Precision = %0.2f)' % (i, ave_precision))\n",
        "    roc_ax.plot(fpr, tpr, lw=1, alpha=0.3,\n",
        "              label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
        "    #Append to Global Containers\n",
        "    ave_acc     = np.append(ave_acc, accuracy )\n",
        "    ave_pre     = np.r_[ave_pre, np.array([precision]) ]\n",
        "    ave_rec     = np.r_[ave_rec, np.array([recall])    ]\n",
        "    tot_ave_pre = np.append(tot_ave_pre, ave_precision )\n",
        "    ave_mse     = np.append(ave_mse, mse )\n",
        "    ave_metrics = np.r_[ave_metrics, np.array([[ tn, fp, fn, tp ]])] \n",
        "    if(debug):\n",
        "      print(\"Fold#{}\\taccuracy\\t{:5f}\\tprecision\\t{}\".format(i, accuracy, tot_ave_pre))\n",
        "  # if(debug):\n",
        "  #   print(\"\\n\\nAverage_Accuracy\\t{:5f}\\tAverage_Precision\\t{}\\tAverage_Recall\\t{}\\tAverage_MSE\\t{}\\tAve_Metrics\\t{}\\n\\n\".format(\n",
        "  #       ave_acc.mean(), ave_pre.mean(0), ave_rec.mean(0), ave_mse.mean(),ave_metrics.mean(0)  ))\n",
        "  pre_rec_fig.legend(loc=\"upper right\")\n",
        "  pre_rec_ax.set_xlabel('Recall')\n",
        "  pre_rec_ax.set_ylabel('Precision')\n",
        "  pre_rec_ax.set_title('Precision-Recall Curve')\n",
        "  roc_fig.legend(loc=\"lower right\")\n",
        "  roc_ax.set_xlabel('False Positive Rate')\n",
        "  roc_ax.set_ylabel('True Positive Rate')\n",
        "  roc_ax.set_ylabel('ROC Curve')\n",
        "  return ave_metrics, ave_acc, ave_pre, ave_rec, tot_ave_pre, ave_mse\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "23k9PRTAyWZR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def PlotKMapMetrics(folds, bestModel, data):\n",
        "  print(\"Rendering Confusion Matrix (Process 7 of 7)\")\n",
        "  k_fig = plt.figure()\n",
        "  k_ax     = k_fig.gca()\n",
        "  #Data Preparation\n",
        "  k_range = range(3, K, 2) \n",
        "  dataset_copy         =  list(folds)\n",
        "  #Testing Using Fold 0 as Test Data\n",
        "  test_fold            =  dataset_copy.pop(0)  \n",
        "  dataset_without_fold =  dataset_copy         \n",
        "  dataset_without_fold =  np.array(dataset_without_fold).reshape((-1, data.shape[1]))\n",
        "  X                    = dataset_without_fold[:, bestModel[\"fSelectedIndexes\"] ]\n",
        "  y = dataset_without_fold[:, -1].reshape(-1)\n",
        "  test_data            = test_fold[:, bestModel[\"fSelectedIndexes\"] ]\n",
        "  test_true_label      = test_fold[:, -1].reshape(-1)\n",
        "  #Average Data Containers\n",
        "  all_train_acc = np.array([])\n",
        "  all_test_acc = np.array([])\n",
        "  #Iterate all K's using the Selected Features and Fold 0 as Test Data\n",
        "  for k in k_range:\n",
        "    clf            = KNeighborsClassifier(k)\n",
        "    train_acc      = clf.fit(X, y).score(X, y) \n",
        "    predictions    = clf.predict(test_data)\n",
        "    test_acc       = accuracy_score(test_true_label, predictions)\n",
        "    all_train_acc = np.append(all_train_acc, train_acc)\n",
        "    all_test_acc  = np.append(all_test_acc , test_acc)\n",
        "  k_ax.plot( k_range , all_train_acc)\n",
        "  k_ax.plot( k_range , all_test_acc)\n",
        "  k_fig.legend(('Train', 'Test'), loc='upper right')\n",
        "  k_ax.set_ylabel('Accuracy')\n",
        "  k_ax.set_xlabel('K Value')\n",
        "  # k_ax.set_xlim(0, 1)\n",
        "  # k_ax.set_ylim(0, 1)\n",
        "  k_ax.set_title('Possible K´s with selected features: {}  Final K: {}'.format(bestModel[\"fSelectedIndexes\"], bestModel[\"k\"] ))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EkO1Ni1yfDN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ConfusionMatrix(tn, fp, fn, tp):\n",
        "  conf_fig    = plt.figure()\n",
        "  conf_ax     = conf_fig.gca()\n",
        "  data = [ [tp, fp], [fn, tn] ]\n",
        "  columns = ('Positive', 'Negative')\n",
        "  rows    = ('Positive', 'Negative')\n",
        "  table = conf_ax.table(\n",
        "    cellText=data,\n",
        "    rowLabels=rows,\n",
        "    colLabels=columns,\n",
        "    loc='top')\n",
        "  conf_fig.tight_layout()\n",
        "  conf_fig.patch.set_visible(False)\n",
        "  conf_ax.axis('off')\n",
        "  conf_ax.axis('tight')\n",
        "  # conf_ax.set_ylabel('Predicted')\n",
        "  # conf_ax.set_xlabel('True Classes')\n",
        "  # conf_ax.set_title(\"Confusion Matrix\")\n",
        "  margins = { \"top\" : 0.863, \"bottom\" : 0.081, \"left\": 0.141, \"right\":0.977, \"hspace\":0.31, \"wspace\":0.255}\n",
        "  conf_fig.subplots_adjust(**margins)\n",
        "\n",
        "  print(\"\\n\\n\\n\\nConfusion Matrix\\n\")\n",
        "  df = pd.DataFrame({\n",
        "      \"Predicted\": [\"Positive\", \"Negative\" ],\n",
        "      \"Positive\": [tp, fp],\n",
        "      \"Negative\": [fn, tn]\n",
        "  })\n",
        "  df.set_index(\"Predicted\",drop=True,inplace=True)\n",
        "  print(\"\\t\\tTrue Class\\n\",df.to_string())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HiQSjYywzgRT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# filename               = sys.argv[1]                 #Import data filename\n",
        "filename               = \"A2_t2_dataset.tsv\"                 #Import data filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YP35GX8ozK6A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "436c2657-f0c2-4ed9-ebdb-e2f8bae9f99c"
      },
      "cell_type": "code",
      "source": [
        "#Upload dataset\n",
        "from google.colab import files\n",
        "import os  \n",
        "\n",
        "def upload(filename):\n",
        "\n",
        "  if not (os.path.isfile(filename)):\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "      print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "          name=fn, length=len(uploaded[fn])))\n",
        "  else:\n",
        "    print(filename+\" on drive\")\n",
        "\n",
        "upload(filename)   "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A2_t2_dataset.tsv on drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kCXM-4dpykE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "054b40ca-cc0e-4151-db79-458fa6688a7e"
      },
      "cell_type": "code",
      "source": [
        "data                   = loadDataset(filename)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Dataset (Process 1 of 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ACZDfP90yqQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4abfe47-29ef-4745-9839-082fd77ee99b"
      },
      "cell_type": "code",
      "source": [
        "data                   = OrderByVariance(data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Order and Filter By Variance (Process 2 of 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9EQslWNywM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57eb4aea-e61f-4a33-884a-84203aa44d82"
      },
      "cell_type": "code",
      "source": [
        "folds, n_rows_per_fold = EqualyDistributePositiveAndNegativeAndSplit(data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Split (Process 3 of 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y44A1Pf0yxtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "446f16f8-c7fd-4a59-aa63-374fbebbf4f0"
      },
      "cell_type": "code",
      "source": [
        "bestModel              = CrossValidation(folds, data, K)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation-Selecting Best Model (Process 4 of 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-373401040d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbestModel\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-4081ca4d91ce>\u001b[0m in \u001b[0;36mCrossValidation\u001b[0;34m(folds, data, K)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# predictions                   = clf.predict(test_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mpredictions\u001b[0m                   \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0maccuracy\u001b[0m                      \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_true_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtest_true_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mave_precision\u001b[0m                 \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_true_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YBc8UCwCyzTF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ave_metrics,_,_,_,_,_  = PlotCurves(     folds, bestModel, data )            #Ploting\n",
        "tn, fp, fn, tp         = ave_metrics.mean(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "slcTYAn0y1PS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PlotKMapMetrics(folds, bestModel, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEIZld_Zy_OV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ConfusionMatrix( tn, fp, fn, tp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k3Pm6vk5zAzd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\\n\\nBest_Model\\tK_Value\\t{}\\tSelected_Features\\t{}\\tAccuracy\\t{}\".format(\n",
        "  bestModel[\"k\"], bestModel[\"fSelectedIndexes\"], bestModel[\"Accuracy\"]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
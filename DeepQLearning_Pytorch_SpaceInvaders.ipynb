{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepQLearning-Pytorch-SpaceInvaders.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "cuqUsfeF28vm",
        "2eQ0MQlhw7JO",
        "_LEF8qS-f5VL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubencg195/Pytorch-Tutorials/blob/master/DeepQLearning_Pytorch_SpaceInvaders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zK9yKwBcMMQY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Imports\n",
        "\n",
        "https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Deep%20Q%20Learning/Space%20Invaders/DQN%20Atari%20Space%20Invaders.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "1IFW5W87weYB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import time\n",
        "import gym\n",
        "import math\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhc6iOZzYdSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "cea90902-0c1d-4d16-8a6d-737237719249"
      },
      "cell_type": "code",
      "source": [
        "OS_Windows = False\n",
        "\n",
        "if OS_Windows:\n",
        "    !ECHO %CurrentDir%\n",
        "    drive_path = \"gdrive/My Drive/Colab Notebooks/\"\n",
        "else:\n",
        "    #Install Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    drive_path = \"gdrive/My Drive/Colab Notebooks/\"\n",
        "    !ls  \"gdrive/My Drive/Colab Notebooks/\"\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            " Beginner\t\t\t\t\t    KRAGGLE\n",
            " Books\t\t\t\t\t\t    log_deepq_pytorch.txt\n",
            "'Convolutionary Network Tutorial - Pytorch.ipynb'   model_deepq_pytorch.ckpt\n",
            "'DATA LOADING AND PROCESSING TUTORIAL.ipynb'\t    MUN\n",
            " DeepQLearning-Pytorch.ipynb\t\t\t    PONG\n",
            "'DeepQ Learning Tutorial.ipynb'\t\t\t    PyTorch\n",
            "'DEEPQ NETWORK SPACE INVADERS.ipynb'\t\t    STATISTICS\n",
            " Intermidiate\t\t\t\t\t    Theory\n",
            "'Keras Tutorial'\t\t\t\t    Udacity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DKsS_afGwtJL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QgxjOBwBwvCs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "#import torchvision.transforms as T\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p-r-64kjMReY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "luCNGmE-JZnh",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "91d83c1d-2235-4928-d27c-70d9b962aca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "#Environment\n",
        "env_name = 'SpaceInvaders-v0' #@param [\"DoomBasic-v0\", \"Breakout-v0\", \"Pong-v0\"] {allow-input: true}\n",
        "\n",
        "env = gym.make(env_name)\n",
        "\n",
        "print(\"Action Space: \", env.action_space.n)\n",
        "print(\"Action Space: \", env.observation_space.shape)\n",
        "\n",
        "possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist()) \n",
        "print(\"Possible Actions: \\n\", possible_actions)\n",
        "\n",
        "\n",
        "### MODEL HYPERPARAMETERS\n",
        "frame_width  = 84                #@param {type:\"number\"} \n",
        "frame_height = 110               #@param {type:\"number\"} \n",
        "\n",
        "### PREPROCESSING HYPERPARAMETERS\n",
        "# Number of frames stacked\n",
        "stack_size = 4                   #@param {type:\"number\"}              \n",
        "state_size = [frame_height, frame_width, stack_size]        # Our input is a stack of 4 frames hence 110x84x4 (Width, height, channels)\n",
        "\n",
        "# 6 possible actions\n",
        "##action_size = env.action_space.n   #@param {type:\"raw\"}\n",
        "action_size = 6   #@param {type:\"raw\"}\n",
        "\n",
        "# Alpha (aka learning rate)\n",
        "learning_rate =  0.00025         #@param {type:\"number\"}      \n",
        "\n",
        "### TRAINING HYPERPARAMETERS\n",
        "\n",
        "# Total episodes for training\n",
        "total_episodes = 2000              #@param {type:\"number\"}\n",
        "# Max possible steps in an episode\n",
        "max_steps = 50000                #@param {type:\"number\"} \n",
        "# Batch size\n",
        "batch_size = 10                #@param {type:\"number\"}              \n",
        "\n",
        "# Exploration parameters for epsilon greedy strategy\n",
        "\n",
        "# exploration probability at start\n",
        "explore_start = 1.0              #@param {type:\"number\"}\n",
        "# minimum exploration probability \n",
        "explore_stop = 0.01              #@param {type:\"number\"}\n",
        "# exponential decay rate for exploration prob\n",
        "decay_rate = 0.00001             #@param {type:\"number\"}         \n",
        "\n",
        "# Q learning hyperparameters\n",
        "# Discounting rate\n",
        "gamma = 0.9                      #@param {type:\"number\"}                \n",
        "\n",
        "### MEMORY HYPERPARAMETERS\n",
        "\n",
        "# Number of experiences stored in the Memory when initialized for the first time\n",
        "pretrain_length = batch_size  \n",
        "# Number of experiences the Memory can keep\n",
        "memory_size = 1000000            #@param {type:\"number\"}       \n",
        "\n",
        "\n",
        "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
        "training = False                 #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
        "episode_render = False           #@param [\"False\", \"True\"] {type:\"raw\"}\n",
        "\n",
        "# Here we create an hot encoded version of our actions\n",
        "# possible_actions = [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0]...]\n",
        "\n",
        "# We stack 4 frames\n",
        "stack_size = 4  #@param {type:\"number\"}       \n",
        "\n",
        "target_update = 10 #@param {type:\"number\"}       \n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Space:  6\n",
            "Action Space:  (210, 160, 3)\n",
            "Possible Actions: \n",
            " [[1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cuqUsfeF28vm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "9PUHiC9jO_Fu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Stack frames**\n",
        "\n",
        "As explained in this really good article we stack frames.\n",
        "\n",
        "https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/\n",
        "\n",
        "Stacking frames is really important because it helps us to give have a sense of motion to our Neural Network.\n",
        "\n",
        "BUT, we don't stack each frames, we skip 4 frames at each timestep. This means that only every fourth frame is considered. And then, we use this frame to form the stack_frame.\n",
        "\n",
        "The frame skipping method is already implemented in the library.\n",
        "\n",
        "First we preprocess frame\n",
        "Then we append the frame to the deque that automatically removes the oldest frame\n",
        "Finally we build the stacked state\n",
        "This is how work stack:\n",
        "\n",
        "For the first frame, we feed 4 frames\n",
        "At each timestep, we add the new frame to deque and then we stack them to form a new stacked frame\n",
        "And so on stack\n",
        "If we're done, we create a new stack with 4 new frames (because we are in a new episode)."
      ]
    },
    {
      "metadata": {
        "id": "IhmIM3ty2-R-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage import transform      # Help us to preprocess the frames\n",
        "from skimage.color import rgb2gray # Help us to gray our frames\n",
        "import matplotlib.pyplot as plt    # Display graphs\n",
        "import warnings                    # This ignore all the warning messages that are normally printed during the training because of skiimage\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def preprocess_frame(frame, display=False):\n",
        "  \"\"\"\n",
        "  Reduce complexity\n",
        "  Steps:\n",
        "  1. Grayscale\n",
        "  2. Crop\n",
        "  3. Normalize \n",
        "  4. Resize\n",
        "  \"\"\" \n",
        "  gray       = rgb2gray(frame)\n",
        "  cropped    = gray[8:-12, 4:-12] \n",
        "  normalized = cropped/255.0 \n",
        "  resized    = transform.resize(normalized, [110,84])\n",
        "  \n",
        "  if display: \n",
        "\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=5, sharey=True, sharex=True, figsize=(25,50))\n",
        "\n",
        "    plt.subplot(1, 5, 1)\n",
        "    plt.imshow(frame)\n",
        "    \n",
        "    plt.subplot(1, 5, 2)\n",
        "    plt.imshow(gray)\n",
        "    \n",
        "    plt.subplot(1, 5, 3)\n",
        "    plt.imshow(cropped)\n",
        "    \n",
        "    plt.subplot(1, 5, 4)\n",
        "    plt.imshow(normalized)\n",
        "    \n",
        "        \n",
        "    plt.subplot(1, 5, 5)\n",
        "    plt.imshow(resized)\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    #print(\"New  Shape: \", resized.shape)\n",
        "\n",
        "  return resized # 110x84x1 frame\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T_smLEsFO3qI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def stack_frames(stacked_frames, state, is_new_episode):\n",
        "    # Preprocess frame\n",
        "    frame = preprocess_frame(state)\n",
        "    \n",
        "    if is_new_episode:\n",
        "        # Clear our stacked_frames\n",
        "        stacked_frames = deque([np.zeros((110,84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "        \n",
        "        # Because we're in a new episode, copy the same frame 4x\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        stacked_frames.append(frame)\n",
        "        \n",
        "        # Stack the frames\n",
        "        stacked_state = np.stack(stacked_frames, axis=2)\n",
        "        \n",
        "    else:\n",
        "        # Append frame to deque, automatically removes the oldest frame\n",
        "        stacked_frames.append(frame)\n",
        "        \n",
        "        # Build the stacked state (first dimension specifies different frames)\n",
        "        stacked_state = np.stack(stacked_frames, axis=2) \n",
        "\n",
        "        #print(\"stacked_frames shape\", len(stacked_frames), stacked_frames[0].shape )\n",
        "        #print(\"stacked_state shape\", stacked_state.shape)\n",
        "        #Output \n",
        "        #stacked_frames shape 4 (110, 84)\n",
        "        #stacked_state shape (110, 84, 4)\n",
        "    \n",
        "    return stacked_state, stacked_frames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WjcvjrB6gqt_",
        "colab_type": "code",
        "outputId": "e4780acf-86f9-4603-f238-9683f391dd4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        }
      },
      "cell_type": "code",
      "source": [
        "obs = env.reset()\n",
        "print(\"Shape\",  obs.shape )\n",
        "preprocess_frame(obs, display=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape (210, 160, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABZkAAAFfCAYAAAAszcLlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzJIkSZIkSZKkQZHRDgAAAAdJREFUof0/uswKQTO5fjgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4a8fe0ad68>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.00151918, 0.00151918, 0.00151918, ..., 0.00147554, 0.        ,\n",
              "        0.        ],\n",
              "       [0.00136726, 0.00136726, 0.00029298, ..., 0.00132799, 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.00115   , 0.00115   ,\n",
              "        0.00115   ],\n",
              "       [0.000805  , 0.000805  , 0.00116643, ..., 0.001265  , 0.001265  ,\n",
              "        0.001265  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "2eQ0MQlhw7JO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Deep Q Network"
      ]
    },
    {
      "metadata": {
        "id": "iOGL5AYs1vWz",
        "colab_type": "code",
        "outputId": "ad35fa47-1577-4cab-e4f7-6f406dd1eeb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "def outputSize(in_size, kernel_size, stride, padding):\n",
        "    output = int((in_size - kernel_size + 2*(padding)) / stride) + 1\n",
        "    return (output)\n",
        "\n",
        "#Input (3, 110, 84) Conv, Output specified = 18 for batch size. for Maxpool layer number 1 remains unchanged\n",
        "print(\"Convolution #1\", (32,\n",
        "       outputSize(in_size=110, kernel_size=8, stride=4, padding=1 ),\n",
        "       outputSize(in_size=84 , kernel_size=8, stride=4, padding=1 ),\n",
        "      ))\n",
        "\n",
        "#Input (32, 27, 20) Conv, Output specified = 18 for batch size. for Maxpool layer number 1 remains unchanged\n",
        "print(\"Convolution #2\", (64,\n",
        "       outputSize(in_size=27 , kernel_size=4, stride=2, padding=0 ),\n",
        "       outputSize(in_size=20 , kernel_size=4, stride=2, padding=0 ),\n",
        "      ))\n",
        "\n",
        "#Input (64, 12, 9) Conv, Output specified = 18 for batch size. for Maxpool layer number 1 remains unchanged\n",
        "print(\"Convolution #3\", (128,\n",
        "       outputSize(in_size=12, kernel_size=3, stride=2, padding=0 ),\n",
        "       outputSize(in_size=9 , kernel_size=3, stride=2, padding=0 ),\n",
        "      ))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Convolution #1 (32, 27, 20)\n",
            "Convolution #2 (64, 12, 9)\n",
            "Convolution #3 (128, 5, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tIXD2ymqw89u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeepQ(nn.Module):\n",
        "  def __init__(self, learning_rate, num_actions, input_shape ):\n",
        "    super(DeepQ, self).__init__()\n",
        "    self.conv1  = nn.Conv2d(4,   32 , kernel_size=8, stride=4, padding=1 )\n",
        "    self.bn1    = nn.BatchNorm2d(32)\n",
        "    \n",
        "    self.conv2  = nn.Conv2d(32,   64 , kernel_size=4, stride=2, padding=0 )\n",
        "    self.bn2    = nn.BatchNorm2d(64)\n",
        "    \n",
        "    self.conv3  = nn.Conv2d(64,   128, kernel_size=3, stride=2, padding=0 )\n",
        "    self.bn3    = nn.BatchNorm2d(128)\n",
        "    \n",
        "    self.fc1    = nn.Linear(128 * 5 * 4  , 512)\n",
        "    self.fc2    = nn.Linear(512          , num_actions)\n",
        "    \n",
        "    self.optim  = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "    self.loss   = nn.MSELoss()\n",
        "    self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "    self.to(self.device)\n",
        "    \n",
        "  def forward(self, obs):\n",
        "    #print(\"Forward Input Shape\", obs.shape)\n",
        "    obs     =obs.to(self.device)\n",
        "    obs     = obs.view(-1, 4, 110, 84 )\n",
        "    obs     = F.relu(self.bn1(self.conv1(obs)))\n",
        "    obs     = F.relu(self.bn2(self.conv2(obs)))\n",
        "    obs     = F.relu(self.bn3(self.conv3(obs)))\n",
        "    obs     = obs.view(-1, 128 * 5 * 4 )\n",
        "    obs     = F.relu(self.fc1(obs))\n",
        "    \n",
        "    actions = self.fc2(obs) #No Relu, raw data represents Q(s, a) value\n",
        "    return actions\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_LEF8qS-f5VL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Memory"
      ]
    },
    {
      "metadata": {
        "id": "N1yQnioNFcDL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import deque# Ordered collection with ends\n",
        "class Memory():\n",
        "  def __init__(self, max_size):\n",
        "    self.buffer = deque(maxlen = max_size)\n",
        "    \n",
        "  def add(self, experience):\n",
        "    self.buffer.append(experience)\n",
        "   \n",
        "  def len(self):\n",
        "    return len(self.buffer)\n",
        "  \n",
        "  def sample(self, batch_size):\n",
        "#     print('Buffer Size', len(self.buffer) )\n",
        "    return random.sample(self.buffer, batch_size)\n",
        "#     buffer_size = len(self.buffer)\n",
        "#     index       = np.random.choice(\n",
        "#         np.arange(buffer_size), \n",
        "#         size    = batch_size,\n",
        "#         replace = False \n",
        "#     )\n",
        "#     return [self.buffer[i] for i in index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n718lFeM18xc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Agent"
      ]
    },
    {
      "metadata": {
        "id": "chWxq6Ni17zx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "  def __init__(self, \n",
        "                  stack_size,\n",
        "                  state_size,\n",
        "                  action_size,\n",
        "                  learning_rate,\n",
        "                  total_episodes,\n",
        "                  max_steps,\n",
        "                  batch_size,\n",
        "                  explore_start,\n",
        "                  explore_stop,\n",
        "                  decay_rate,\n",
        "                  gamma,\n",
        "                  pretrain_length,\n",
        "                  memory_size,\n",
        "                  training ,\n",
        "                  episode_render,\n",
        "                  possible_actions,\n",
        "                  target_update\n",
        "              ):\n",
        "    \n",
        "    self.stack_size         = stack_size\n",
        "    self.state_size         = state_size\n",
        "    self.action_size        = action_size\n",
        "    self.learning_rate      = learning_rate\n",
        "    self.total_episodes     = total_episodes\n",
        "    self.max_steps          = max_steps\n",
        "    self.batch_size         = batch_size\n",
        "    self.explore_start      = explore_start\n",
        "    self.explore_stop       = explore_stop\n",
        "    self.decay_rate         = decay_rate\n",
        "    self.gamma              = gamma\n",
        "    self.pretrain_length    = pretrain_length\n",
        "    self.memory_size        = memory_size\n",
        "    self.training           = training\n",
        "    self.episode_render     = episode_render\n",
        "    self.possible_actions   = possible_actions\n",
        "    self.target_update      = target_update\n",
        "    self.Q_eval             = DeepQ(\n",
        "        learning_rate       =  self.gamma\n",
        "        ,num_actions        =  self.action_size\n",
        "        ,input_shape        =  self.state_size\n",
        "    )\n",
        "    self.Q_target           = DeepQ(\n",
        "        learning_rate       =  self.gamma,\n",
        "        num_actions         =  self.action_size,\n",
        "        input_shape         =  self.state_size\n",
        "    )  \n",
        "     \n",
        "    print(\"Loadinig Models\")\n",
        "      \n",
        "    self.Q_target.load_state_dict(\n",
        "        T.load(\n",
        "            drive_path+\"/model_deepq_pytorch.ckpt\", \n",
        "            map_location=self.Q_target.device\n",
        "        )\n",
        "    )  \n",
        "    self.Q_target.load_state_dict(\n",
        "        T.load(\n",
        "            drive_path+\"/model_deepq_pytorch.ckpt\", \n",
        "            map_location=self.Q_target.device\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    \n",
        "    device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
        "    self.Q_eval.to(device)\n",
        "    self.Q_target.to(device)\n",
        "    \n",
        "\n",
        "    #Target Policy\n",
        "    self.memory = Memory(max_size = self.memory_size)\n",
        "    # Initialize deque with zero-images one array for each image\n",
        "    self.stacked_frames  =  deque(\n",
        "        [np.zeros((110,84), dtype=np.int) for i in range(stack_size)], \n",
        "        maxlen=4\n",
        "    )\n",
        "\n",
        "    \n",
        "    print(\n",
        "      '_'*10 +  'HYPERPARAMETERS'  +   '_'*10  + '\\n'     ,\n",
        "      '\\nstack_size        '      ,self.stack_size        , \n",
        "      '\\nstate_size        '      ,self.state_size        ,\n",
        "      '\\naction_size       '      ,self.action_size       ,\n",
        "      '\\nlearning_rate     '      ,self.learning_rate     ,\n",
        "      '\\ntotal_episodes    '      ,self.total_episodes    ,\n",
        "      '\\nmax_steps         '      ,self.max_steps         ,\n",
        "      '\\nbatch_size        '      ,self.batch_size        ,\n",
        "      '\\nexplore_start     '      ,self.explore_start     ,\n",
        "      '\\nexplore_stop      '      ,self.explore_stop      ,\n",
        "      '\\ndecay_rate        '      ,self.decay_rate        ,\n",
        "      '\\ngamma             '      ,self.gamma             ,\n",
        "      '\\npretrain_length   '      ,self.pretrain_length   ,\n",
        "      '\\nmemory_size       '      ,self.memory_size       ,\n",
        "      '\\ntraining          '      ,self.training          ,\n",
        "      '\\nepisode_render    '      ,self.episode_render    ,\n",
        "      '\\ntarget_update     '      ,self.target_update     ,\n",
        "      '\\npossible_actions\\n'      ,self.possible_actions  ,\n",
        "      '\\n'\n",
        "    )\n",
        "  \n",
        "  def save_log(self, episode,total_reward, explore_probability, loss, running_loss , time, step, exp, running, action ):\n",
        "    with open(drive_path+\"/log_deepq_pytorch.txt\" , \"a\") as myfile:\n",
        "      log = '{} Episode: {} Total reward: {} Explore P: {:.4f} nTraining RunningLoss {:.4f} Loss {:.4f} Time Lapse {} Min. Step: {} {} Action {}'.format( \n",
        "          running, episode,total_reward, explore_probability, running_loss , loss , time, step, exp, action\n",
        "      ) \n",
        "      myfile.write(log)\n",
        "      print(log)\n",
        "      \n",
        "  def predict_action(self, decay_step, state):\n",
        "    #EPSILON GREEDY STRATEGY\n",
        "    #Choose action a from state s using epsilon greedy\n",
        "    #First we randomize a number\n",
        "    exp_exp_tradeoff       = np.random.rand()\n",
        "    explore_probability    = self.explore_stop         \\\n",
        "    + (self.explore_start  - self.explore_stop  )      \\\n",
        "    * np.exp(-decay_rate   * decay_step    )\n",
        "    \n",
        "    if(explore_probability > exp_exp_tradeoff):\n",
        "      #Make a random action (Exploration)\n",
        "      choice               = random.randint(1, len(self.possible_actions)) - 1\n",
        "      action               = self.possible_actions[choice]\n",
        "\n",
        "    else:\n",
        "      #Get action from QNet (Explotation)\n",
        "      action   =  self.Q_eval.forward(T.Tensor(state))\n",
        "      action   =  T.argmax(action).item()\n",
        "      \n",
        "    return action, explore_probability, (explore_probability > exp_exp_tradeoff)\n",
        "  \n",
        "  def train(self):\n",
        "    #Initialize the decay_rate (This will reduce epsilon)\n",
        "    self.decay_step        = 0\n",
        "    self.start_time        = time.time()\n",
        "    \n",
        "    self.state             = env.reset()\n",
        "    preprocess_frame(self.state, display=True)\n",
        "    \n",
        "    self.reward_list       = []\n",
        "    \n",
        "    for episode in range(self.total_episodes):\n",
        "      #Set Step to 0\n",
        "      self.step            = 0\n",
        "      \n",
        "\n",
        "      #Initialize the rewards of the episode\n",
        "      self.episode_rewards = []\n",
        "      \n",
        "      #Make a new episode and observe \n",
        "      self.state                  = env.reset()\n",
        "      \n",
        "      #Remember that stack frame function also call our preprocess function\n",
        "      self.state, self.stacked_frames  = stack_frames(\n",
        "          self.stacked_frames, \n",
        "          self.state, \n",
        "          is_new_episode=True\n",
        "      )\n",
        "      \n",
        "      while self.step < self.max_steps:\n",
        "        self.step       += 1\n",
        "        \n",
        "        #Increase the decay step\n",
        "        self.decay_step += 1\n",
        "        \n",
        "        #Predict the action to take and take it\n",
        "        self.action, self.explore_probability, self.exploration_vs_explotation = self.predict_action(\n",
        "            self.decay_step,\n",
        "            self.state\n",
        "        )\n",
        "        \n",
        "        #Perform the action and get the next_state, reward, and done info\n",
        "        self.next_state, self.reward, self.done, _ = env.step(np.argmax(self.action))\n",
        "        \n",
        "        if episode_render:\n",
        "          env.render()\n",
        "          \n",
        "        #Add the reward to the total reward\n",
        "        self.episode_rewards.append(self.reward)\n",
        "        \n",
        "        if self.done:\n",
        "          #The episode ends so no next state\n",
        "          self.next_state = np.zeros( (110, 84) , dtype=np.int )\n",
        "          \n",
        "          self.next_state, self.stacked_frames = stack_frames(\n",
        "              self.stacked_frames, \n",
        "              self.next_state,\n",
        "              is_new_episode=False\n",
        "          )\n",
        "          \n",
        "          #Set Step = max_steps to end the episode\n",
        "          self.step = self.max_steps\n",
        "          \n",
        "          #Get the total reward of the episode\n",
        "          total_reward = np.sum(self.episode_rewards)\n",
        "          \n",
        "          self.save_log(\n",
        "              episode,\n",
        "              total_reward,\n",
        "              self.explore_probability,\n",
        "              self.loss.item() / self.step ,\n",
        "              self.loss.item() , \n",
        "              ( time.time() - self.start_time) / 60,\n",
        "              self.step,\n",
        "              \"Exploration\"  if (self.exploration_vs_explotation) else \"Explotation\",\n",
        "              \"Done:\",\n",
        "              np.argmax(self.action)\n",
        "          )\n",
        "          \n",
        "          self.reward_list.append( (episode, total_reward) )\n",
        "          \n",
        "          #Store transition <st,at,rt+1,st+1> in memoryD\n",
        "          self.memory.add( \n",
        "              (self.state, self.action, self.reward, self.next_state, self.done)\n",
        "          )\n",
        "          \n",
        "        else:\n",
        "          #Stack the frame of the next_state\n",
        "          self.next_state, stacked_frames = stack_frames(\n",
        "            self.stacked_frames, \n",
        "            self.next_state,\n",
        "            is_new_episode=False\n",
        "          )\n",
        "          \n",
        "          #Add experence to memory\n",
        "          self.memory.add( \n",
        "              (self.state, self.action, self.reward, self.next_state, self.done)\n",
        "          )\n",
        "          \n",
        "          #st+1 is now our current state\n",
        "          self.state = self.next_state\n",
        "          \n",
        "        ###LEARNING\n",
        "        #obtain random mini-batch from memory\n",
        "        if self.memory.len() > self.batch_size:\n",
        "          \n",
        "          batch              = self.memory.sample(self.batch_size)\n",
        "          states_mb          = T.FloatTensor(np.array([each[0] for each in batch])).to(self.Q_eval.device)\n",
        "          #actions_mb         = np.array([each[1] for each in batch])\n",
        "          rewards_mb         = T.FloatTensor(np.array([each[2] for each in batch])).to(self.Q_eval.device)\n",
        "          next_states_mb     = T.FloatTensor(np.array([each[3] for each in batch])).to(self.Q_eval.device)\n",
        "          dones_mb           = np.array([each[4] for each in batch])\n",
        "\n",
        "          target_Qs_batch    = []\n",
        "          \n",
        "          #Get Q values for next state\n",
        "          self.Qs_next_state       = self.Q_target.forward(next_states_mb)\n",
        "          self.Qs_state            = self.Q_eval.forward(states_mb)\n",
        "          self.Qtarget             = T.zeros_like(self.Qs_next_state) \n",
        "         \n",
        "          #Set Q_target = r if the episode ends at s+1, otherwise\n",
        "          #set Q_target = r + gamma*maxQ(s', a')\n",
        "          for i in range  (0, len(batch)):\n",
        "            terminal = dones_mb[i]\n",
        "            \n",
        "            #if we are in a terminal state only equals reward\n",
        "            if terminal:\n",
        "              target = rewards_mb[i]\n",
        "            else:\n",
        "              target = rewards_mb[i] + gamma * T.max(self.Qs_next_state[i])\n",
        "              \n",
        "            target_Qs_batch.append(target)\n",
        "            #shape (batch_size, num_actions) we want first dim\n",
        "            #We want the loss function to be zero for every action except the maxAction\n",
        "            maxAction                 = T.argmax(self.Qs_next_state[i]).to(self.Q_eval.device)\n",
        "            self.Qtarget[i,maxAction] = target\n",
        "            \n",
        "    \n",
        "          self.loss       = self.Q_eval.loss(\n",
        "              self.Qtarget, \n",
        "              self.Qs_state\n",
        "          ).to(self.Q_eval.device)\n",
        "          # Optimize the model\n",
        "          self.Q_eval.optim.zero_grad()\n",
        "          self.loss.backward()\n",
        "          self.Q_eval.optim.step()\n",
        "         \n",
        "          \n",
        "          #Get the total reward of the episode\n",
        "          total_reward = np.sum(self.episode_rewards)\n",
        "          \n",
        "          if(self.step % 500 == 0):\n",
        "            self.save_log(\n",
        "                episode,\n",
        "                total_reward,\n",
        "                self.explore_probability,\n",
        "                self.loss.item() / 500 , \n",
        "                self.loss.item() , \n",
        "                ( time.time() - self.start_time) / 60,\n",
        "                self.step,\n",
        "                \"Exploration\"  if (self.exploration_vs_explotation) else \"Explotation\",\n",
        "                \"Running:\",\n",
        "                np.argmax(self.action)\n",
        "            )\n",
        "            \n",
        "          \n",
        "#           print(self.Qtarget.shape,  self.Qs_state.shape, self.batch_size, states_mb.shape )\n",
        "#           return;\n",
        "\n",
        "        \n",
        "      # Save model every 5 episodes\n",
        "      if episode % target_update == 0:\n",
        "          T.save(self.Q_eval.state_dict(), drive_path+\"/model_deepq_pytorch.ckpt\" )\n",
        "          self.Q_target.load_state_dict(self.Q_eval.state_dict())\n",
        "          print(\"Saving Model and Updating Target\")\n",
        "          \n",
        "          \n",
        "  \n",
        "  def play(self):\n",
        "    state                  = env.reset()\n",
        "    totalScore             = 0\n",
        "    self.decay_step        = 0\n",
        "    \n",
        "    \n",
        "    #Load the model\n",
        "    filename   = \"./models/model.ckpt\" \n",
        "    if( os.path.isfile(filename) ):\n",
        "      self.Q_eval.load_state_dict(torch.load(filename))\n",
        "    \n",
        "    #Make a new episode and observe \n",
        "    state                  = env.reset()\n",
        "\n",
        "    #Remember that stach frame function also call our preprocess function\n",
        "    state, stacked_frames  = stack_frames(stacked_frames, state, is_new_episode=True)\n",
        "      \n",
        "    for episode in range(10):\n",
        "      \n",
        "      self.step              = 0\n",
        "      \n",
        "      \n",
        "      while self.step < self.max_steps:\n",
        "        decay_step += 1\n",
        "        step += 1\n",
        "\n",
        "        #Predict the action to take and take it\n",
        "        action, explore_probability = predict_action(\n",
        "            decay_step,\n",
        "            state\n",
        "        )\n",
        "\n",
        "        #Perform the action and get the next_state, reward, and done info\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        if episode_render:\n",
        "          env.render()\n",
        "\n",
        "        if not done:\n",
        "          next_state, stacked_frames = stack_frames(\n",
        "            stacked_frames, \n",
        "            next_state,\n",
        "            is_new_episode=False\n",
        "          )\n",
        "\n",
        "          #Add experence to memory\n",
        "          memory.add( (state, action, reward, next_state, done) )\n",
        "\n",
        "          #st+1 is now our current state\n",
        "          state = next_state\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XIAVtz51_AL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Train"
      ]
    },
    {
      "metadata": {
        "id": "E7dQgZoWY3zm",
        "colab_type": "code",
        "outputId": "6a8ef6f6-13fe-4da6-c90a-73da161443a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3496
        }
      },
      "cell_type": "code",
      "source": [
        "agent = Agent(  \n",
        "    stack_size       = stack_size,\n",
        "    state_size       = state_size,\n",
        "    action_size      = action_size,\n",
        "    learning_rate    = learning_rate,\n",
        "    total_episodes   = total_episodes,\n",
        "    max_steps        = max_steps,\n",
        "    batch_size       = batch_size,\n",
        "    explore_start    = explore_start,\n",
        "    explore_stop     = explore_stop,\n",
        "    decay_rate       = decay_rate,\n",
        "    gamma            = gamma,\n",
        "    pretrain_length  = pretrain_length,\n",
        "    memory_size      = memory_size,\n",
        "    training         = training, \n",
        "    episode_render   = episode_render,\n",
        "    possible_actions = possible_actions,\n",
        "    target_update    = target_update\n",
        ")\n",
        "agent.train()\n",
        "#agent.play()\n",
        "# obs = env.reset()\n",
        "# state, stacked_frames  = stack_frames(stacked_frames, obs, is_new_episode=True)\n",
        "# agent.predict_action(0, state)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loadinig Models\n",
            "__________HYPERPARAMETERS__________\n",
            " \n",
            "stack_size         4 \n",
            "state_size         [110, 84, 4] \n",
            "action_size        6 \n",
            "learning_rate      0.00025 \n",
            "total_episodes     2000 \n",
            "max_steps          50000 \n",
            "batch_size         10 \n",
            "explore_start      1.0 \n",
            "explore_stop       0.01 \n",
            "decay_rate         1e-05 \n",
            "gamma              0.9 \n",
            "pretrain_length    10 \n",
            "memory_size        1000000 \n",
            "training           False \n",
            "episode_render     False \n",
            "target_update      10 \n",
            "possible_actions\n",
            " [[1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1]] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABZkAAAFfCAYAAAAszcLlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XuUXFWd9/9PJUEIHRU6IBAIF7ns\nCIkuicolIAkXR2Dml2ECyBiRAI4woKPkych08AYPpJeK8PggQ2AJiQRc4ZLlD9AHZiAyT5CAMoAQ\niNkBfxGCkYs0okASEqjfH93n9Enl1OWcs8+13q+1WNk5VfX97vp25Uv37l27avV6XQAAAAAAAAAA\nxDEi7wkAAAAAAAAAAMqLRWYAAAAAAAAAQGwsMgMAAAAAAAAAYmORGQAAAAAAAAAQG4vMAAAAAAAA\nAIDYWGQGAAAAAAAAAMQ2Ku8JAAAAVIEx5kpJh0qqS/qKtfaRnKcEoIvQgwAAQJ6cLzLzzQ2AvNB/\nAOTFGHOUpP2ttYcZYz4k6QZJh+U8LQBdgh4EAADy5vS4jOA3N5LOlvS/XcYHgGboPwBydoyk/1eS\nrLW/lbSjMeZ9Le5f5z/+479S/1c09CD+47/u+q9QjDFXGmMeMsYsN8Z8PO/5AMiH6zOZI31zU6vV\n6k899VS9Vqtl/h95yUve5P857h9JRf3hSsr/m0P+4z/+S/Zfkewq6ZXA318ZugYAWaAHAcgFm30A\neFwfl7GrpEcDf/e+uflL2J1XrFihiRMnql7P5+dE8pKXvJUSqf8AQMpqeU8AQFejBwHIyhabfYwx\nOxpj3metbfVzWNf/8AqUXOj3GWl/8F/Lb24mTZqker2uWi3774HIS17yuslbYPxwBSBL67TlrsFx\nkv7Y7M5HHHGEfvnLX+qII45wkvyXv/ylkzhl4apunqLUr1arOf1/esH/P+2c6++FSlY/elCGqtqD\nJLf/jkr2byixLu5BbPYBIMn9cRmRvrkBAIfoPwDy9J+STpYkY8zBktZZa/+a75QAdBF6EICiYLMP\n0KVc72T+T0kXS7qWb24AZIz+AyA31trlxphHjTHLJb0r6fxW9/d2rWWxe63djruouxlbzTnu7r5m\nc2iWq0i7/lzydq1lsXut1Y67OLupm805yc6+ZvNolqtEu/6cK2sPirObmh6Urqz+HRW9B7WaAz1o\nK5E3+5x66qm69dZbdeqppzqZwK233hp6fePGjf743XffTZxn22239ccjRgzv2QzGDuYcPXq01q9f\nHzlPMHYwp8dV3TzN6peVF154wR8fcsghieNNmzbNH990002h93nzzTcjxezp6Wn5mJ6enq2uBb/2\nLl5/0uBrStryNeKqfn/4wx+0++67d1S/ZpwuMkf95gYAXKH/AMibtfbf8p4DgO5FDwKQEzb7AJCU\nwpnMfHMDIC/0HwBl0eo81GY75NrtBoxzW5T7dCJJnCiPjVuLZo8ryq7EVmcyx9ml12pXXbsdd652\n5CWNE+XxcWsRdbdiFRSpB7n890cPSi7qv4cq96Coj+3WHsRmHwCetD/4DwAAAA3ivFU97iJEnEWN\nLBdQ4ix2xa1FkRZywsQ5LiPuIkScRY04CyhJFl2yOi6jLAs5LtGDtnwMPWhY1H8PVe1BrR5LD9pa\n1M0+O+200xZ/ei699FJ/3NvbK0kaGBjwr33961+PNK/g0RWbNm2K9Ngw22yzjT9udlzGW2+95Y9H\njx69xd/j5Ak7LqOxbp6w+knJapiFUaOGlyb33HPP0Ps89NBDW137yle+4o9//etf++OxY8e2zfn6\n669HmaJ6enpaPqbdcRkbNmyIlK+Z97znPZK2fP3FrZ+0ZQ29x3dSv2Zcf/AfAAAAAAAAAKCLsJMZ\nAAAgY0V6q7qrxyTNxVvVi3VcRp6PCT6O4zLSQQ/a+jH0oEFFOS4jz8fEfSw9CEC3Y5EZAAAAAAAA\nmTjqqKO2+NPjHQXQ7Frj/dtZs2aNPw4eGeEdJfGRj3wk9HH3339/6PVDDjnEHwePKHj77bf98ZNP\nPumPp02bpieffFLTpk0LjffEE0+0nF+zOTarQ1j9Gq9HrWEWtt9+e3980kkndfy4T37yk/549913\n98f77rtv28eGfY2nT5/uj8eMGeOP33jjDUnS+973Pt1xxx2h8WbOnLnVtaeeesofr1271h+PHz/e\nHwefQ9DNN98cet2bY/BIlbj1C8t/0kkndVS/ZlhkBgAAyBjnoW75GM5DHcSZzFs+jjOZ00MP2vIx\n9KBhnMnc/rH0IAAIxyIzAABAxnir+taP4a3qHJcR9jiOy0gHPWjrx9CDBnFcRvzH0oM694lPfGKL\nPz3tdjI33r+d4E7hZ5991h/vt99+kqLvZP7oRz/qj4O7R4M7mYOPnTZtmu6///6OdjKHza/ZHJvV\noZOdzFFrmIXghxueeOKJHT/uYx/7mD+eMGGCPw7uQm7mrrvu2urapz71qdAY69ev15gxY7R+/frQ\nx0nhO5n/67/+yx+vXLnSHx944IH+uNlO5mZ5vDkG5xe3ftKWNfQe30n9muGD/wAAAAAAAAAAsbGT\nGQAAIGO8VX3Lx/BW9UEcl7Hl4zguIz30oC0fQw8axnEZ7R9LDwKAcIVcZD740oOdxHns6485iVM0\ncevT+Lg863PjvEOdxPn83IedxCmaOPUJe0xV65O2Vj/YRFGGHyTiiFOfsB/e8qxPqx84oqjqDwVR\n6xN1IQgAAADda5999tniz1aCRz10cv+gxx9/3B8/8sgj/vivf/2rJOnzn/986ON+8YtfhF4/77zz\nQq9v2LAh9LGXXHKJfvGLX+iSSy6JNb9mc4xahyQ1zELwuIeDDjqo48fttddesXPecsstW137zne+\nE3rft956y/8z7HGStHjx4q2uPfDAA/74vvvu88fHHntsrPk1m2Pc+klb1zDq4xsVcpEZAACgylrt\nnIuD81CTKcovBVvt3o2jzOehuj6TOckcqogetPVj6EGDXP47KnMPivNYehCAblfIRea0d9h6O3qT\n7phuNs92cTvN2yx+rPpcVKyd3VnssHWxW7rZPFvFjpK3Wfyo9Tm9j13LLqX9jb6rH+zifjBPp3mr\n/BbRLL5pd/GDRtS3fkZdnHL5dk9+EIomzqJGXO3+zUftR3Hf4h5nDq77UNHFWViNq91byOO8oyFq\nnk5iZnFcRjcqSg+K8/0QPShdWf07KnoPajUHehAAhCvkInOzRdioi7otF2lTXHRtGddB3rj1KcNx\nGVEXdVstrKa56NostqvF3jjPl+My3Il6nl/U+6f9g127uEnzxqlPWY7LiLOo20yaP2ikndfVOYn8\nsAUAAIBGa9as0T777KM1a9Y4idfsCIiPfvSj/vi9733vVrd/85vfDH3c0UcfHXp9u+22a3u98bFH\nH3100zzBOQUft99++4Xe3+Oqbp68j9DYuHGjP3722WcTxxszZow/bnakxmc+85mtrl144YVNYy5e\nvFgXXnhh6OOaOfLII/3x2LFjQ+9z2mmndTw/Sdp+++23uuaqfgcddJCefvrpjurXTCEXmQEAAOBG\nJ7/QcfVLnyRxqrwzsIja/RLI1S+Jksbhl1Xll/Yvv13Fogdlqww9iP4DANEUcpE56g7bqPePurM3\n7Z3VsXZiR5D2zu04ou6wjbMjN8rOXlc7q6PMpVX8OM+XXcvuRP0hI+r9o+7sTXtnddyd2J3K8i25\nncrik9Oj7OxNe2d1Fm/35AcxAAAAAOhetTx/KKzVavWws47SXqSV4p3z5IKLvHHq8+hFj2ryZZM7\nur9LzZ5v2sdllPnrK8V7vov6D+v4/q7U6/Xsi+xWaANMe5G27Dguo/39y65Ex2WUuQdV88UDdI8y\n9x+JHgSUHT0IQJ5Ce9CIrGcBAAAAAAAAAKiOQu5kTlvUnb0ud1a72LkdR9l39sbJG2Vnr6ud1af3\nPeRk53ZUOdaZ36DHUPbjMtCZMh+XUSJl7kGlLz7Q5crcfyR6EFB29CAAeQrtQYVcZOa4jNY4LqP9\n/cv89ZU4LiNDHJcRA8dltL9/2XFcRiaq+eIBukeZ+49EDwLKjh4EIE8clwEAAAAAAAAAcKuQO5nT\nxnEZ2eG4jHjxo+K4jNg4LiPG/dEZjsvIRJl7UOmLD3S5MvcfiR4ElB09CECeyn9cRlTddlxGK2U5\nLiOqbjsuo5nT+x7iuIx4Ih2XEVVVF2nj1Kcsx2VEVYFF2lBR69Os93FcRkvVfPEA3aPM/UeiBwFl\nRw8CkCeOywAAAAAAAAAAuFXIncxpa3ZcRlRRj8uQwncUR40fR9l39sbJG7azN6o4x2VEyctxGbkr\n1HEZUUU9/sJ7TKd5q7oTOysu/k3GOf4iSt4K7MQucw8qffGBLlfm/iPRg4CyowcByFN5jsvIAnnJ\nS14nefnmBkCeytyD6D9AuZW5/0j0IKDs6EEA8sRxGQAAAAAAAAAAt1hkBgAAAAAAAADExiIzAAAA\nAAAAACA2FpkBAAAAAAAAALGxyAwAAAAAAAAAiG1U3AcaY74r6cihGP2S/h9JkyW9OnSX71lrf554\nhgAQgh4EAAAAAABQDLEWmY0x0yRNtNYeZowZK+lxSb+Q1Get/ZnLCQJAI3oQAGSjt7dXkjQwMJBJ\nrqzySNk9p6rmyiIPUMXXdZX7Qpa56EEAUDxxdzIvk/TrofGfJfVIGulkRgDQHj0IAAAAAODcU089\n5Y8nTpyYSc57773XHx933HGp5Zk5c6Y/vvnmm1PJQf26V6xFZmvtO5LeHPrr2ZL+j6R3JH3JGDNb\n0suSvmSt/VOrOCtWrJAk1ev1ONNIjLzkJW85uepBABBX2Y/sabcLzOWOtE5yDQwMJM7VyZxd7X5r\nl8t1/bLMldXrAvGVvf9I9KCk6EH0IAAoothnMkuSMWa6Bhd4PiXpY5Jetdb+xhjzb5K+LelLrR4/\nadIk1et11Wq1JNOIhbzkJa+bvHlK2oMAIA6O7AGQF/oPAAAoqiQf/Pc3ki6S9Glr7euSlgZuvlPS\nNQnnBgBN0YMA5Ki0R/YEd4GF7QhLa/dbFrm8OGnmaowTtusurZ2KWeVqlic4F+SqtP1Hyva1Rg9K\nhh6Eqlm1apU/fvzxxyVJJ598sn/t0Ucf9cdjxoxJnG/RokU6/fTTtWjRIu2///7+9cmTJ/vj22+/\n3R//4z/+Y6w8V199tT8eOXL4fwfnnnuuP54/f74//vGPfxwrT1j9pMEabrPNNtq0aZNfQxf1kwZr\n6PFq6Lp+0nANW9Xv3HPP1fz582PXr1vE/eC/90v6nqRjrbUDQ9eWSPpXa+3/J2mqpKeaRwCA+OhB\nAPJU5iN7gj+gh/2w7vIH+CrmaoxTxVxpf62QTJn7j1TNvpBlLnoQAKDI4u5k/oyknSTdaozxri2Q\ndIsx5i1Jb0g6M/n0ACAUPQhA7sp4ZE+z3WBp7BJrtZsvjVzNnpPLXO2eU1VzscBTPGXsP1L2fSHL\nXPSg9HLRgwCgHOJ+8N91kq4LuYl94wBSRw8CkLeyHtnT7u3bLhcQWsVtvJZ0ASGrXK0WkaqSq91i\nWdJcSK6s/UfK9rVGDypnLnoQ0vLqq6/643/4h3+QpC2Osfja177mj2fMmJE436GHHur/ee+99/rX\nTzvtNH98zz33JM7z7LPP+uPZs2f74+C/m+XLl/vjESNGxMoTVj9psIa///3vtf/++/s1dFE/abiG\nkvwauq6fNFzDdvWbOnVq7Pp1C6oDAAAQQeDInr8NHtljjPng0F2miiN7AKSA/gMAAIoq9gf/AQAA\ndKnSH9kTtiss7IOrXByjEbbTrVkuV3m8XGEfXJXmc2rMW5Vcrr9WSKT0/UeK9loL3iftXPSgYuai\nBwFAObDIHMG8eeM1d+5a4ucYX1JqOdKODySV9jfUxG8fX0rvLZp8cnp5cGQPgLzQfwAgnilTpvhj\n7/vudevW+dcee+wxf/yhD33IH8f93vyGG25Qf3+/brjhhi2uv+c97/HH3/jGN/zxiSee6I9nzZrV\ncZ7+/n5/PG7cOH98xRVX+OOenh5/vNNOO/njKM8trH7ScA1XrVrl19BF/SRtVTvJff2k4Rq2q19P\nT0/s+nULFpmHtFogdbH4SPz28VvFSLqAnXZ8IKlWC6SudobkGX9gYKDw828Vw9XuprTiA0k17kTz\nuH5dBuPnlSvNPFXNxXmoSFMR+kKWuarSF7LMRQ8CgHLgTGYAAAAAAAAAQGxdv5M5uMM1bLeryx20\n3rjxdtfxw+bf15du/CSCMRrjud6FnUZ8IImwM+3afcJ2kvhhn9btMr43Lkv8xhiN8Vzv8k4jPgAA\nAIDogscjBJ1zzjlO81x77bWh15cuXeqPb7vtNqc5Z8+eHXo9eESIC+PGjdPAwMAWtXRdPym8hlnW\nb2BgQB/5yEec169qun6ROSi4ENl4zVX8vr5040vlje/FK3N8IInGDzUJXiN++vG9eGWOD0QRfP2F\n/QIqrVyNqpjLdZ4sc3l5wvKl8bzQvbJ8rRWhL2SZix4EAMgDx2UAAAAAAAAAAGKr1ev1/JLXavV6\nva5arZZ57rC8YcdZBLk4FqKv73n19++ZWvxm+vqeT1znOPWJ+vVtlSNKfZrldRU/at605Zg3+6Ru\n5dcAQ7TbneHqWIhmeVzEb8bFjt2069MuRxnid6Ey96Bc+k/YazDsCJdW90kjV7MjfdLIFXa7qzxV\nyZVWnoopc/+RCtKDOn0XBT2o8zhVyEUP6gg9KKLnnnvOH5988smSpIceesi/tmrVKn980UUX+eM7\n7rgjVr7p06frjjvu0PTp03XZZZf51ydMmOCPDzvsMH98++23++O99tqr4zw33nijP3755Zf98Zw5\nc/zx5Zdf7o8/8IEP+OPPf/7zHecJq580WMNRo0Zp8+bNfg1d1E8arKHHq6Hr+knDNWxVvzlz5ujy\nyy+PXb8KCu1BHJcxpPEIhbCziJOcP0z8aPEb482bNz7R+clpxweSCvtBp3Hs6ocf4reP3xivt7c3\n0fnJaccHOtXu9ZXGETed3p4kd1bPq5M4VcxFX4Ir9KBkitQXssxFDwKAcmCRGQAAAAAAAJUV3N36\nyCOPbHX7xIkT/XGS3beNMVrFCptHVJ3spg3uyo2rXf1GjRrl19BF/TqJ46J+UvsaevVzUceq47iM\nIe2OgpCS7XD14qd1XEa7+Sc9LiNufTr9+rquf9Zf32Z5s8JxGbEV5riMTj7IJMkujrCdv2nEbybN\nozhc5Ch7/C5W5h5UmP4DIJYy9x+JHgSUXW49yBjzXUlHanDTYr+kRyQtkjRS0h8lnW6t3dgmDD0I\nKLfQHsQH/wEAAAAAAKAlY8w0SROttYdJ+rSk/yXpEklXW2uPlPSspLNynCKAHLHIDAAAAAAAgHaW\nSTplaPxnST2Spkq6c+jaXZKOzX5aAIqAM5kDmh2X0MlRC53G7+vbOo/L+GHKEj+LHFk8ByCuZscl\ndHLUQpT4nX6Se9z4jcoSP4scWTwHAAAAIA3W2nckvTn017Ml/R9JfxM4HuNlSbvlMTcA+ev6M5nD\nFheDC5GNt0c9t7fx8Y1nI7uO3xij8SzotOKH3SZ1dlZwqxjt8jcTzJtG/E7yZokzmWPL/SywsMXF\n4EJk4+1Rz+1t93jX8RtjNJ4FnVb8sNvi5mgVP06OtON3uTL3oNz7D4BEytx/JHoQUHa59iBjzHRJ\ncyV9StIz1toPDF3fT9KN1trD24SgBwHlxpnMAAAAAAAAiMcY8zeSLpJ0vLX2dUlvGGNGD928u6R1\nuU0OQK66ficzeclL3kR52cUDIE9l7kH0H6Dcytx/JHoQUHa59CBjzPslPSDpWGvty0PXrpO0zFp7\nkzHmf0t60lr7ozah6EFAuYX2IM5kBgAAAAAAQDufkbSTpFuNMd61MyT9yBhzjqTnJP04p7kByBk7\nmclLXvImycsuHgB5KnMPov8A5Vbm/iPRg4CyowcByBNnMgMAAAAAAAAA3GKRGQAAAAAAAAAQG2cy\nAwAAAAAAoCu8++67kqQNGzaE3r799ts7zffWW2+FXt9uu+388YgRyfeABp+P9xwbYwdzxhWMvWHD\nBm2//fZbPEfX9ZPCa5hl/bbbbjtt2LDBSf2qjEVmAACALtTb2ytJGhgY8MeegYGBVHKFqWIu13my\nzNXb2xv6mkgjF7pblq+1IvSFLHPRgwAAeWCRGQAAoMu0WgQJ3u7iB/pOcmWRJ8tcWdevjLnQ3Yr2\nuqYHdV8uAIB7LDIDAAAAAACgK0ydOlWS9NRTT4XePm/ePH987rnnxsoxf/58nXvuuZo/f77mzp0b\nep+JEyf642XLlsXKs3HjRn+83377+eNmx1f87ne/88fbbrttrJxe/aTBGg4MDGiPPfbwr7monzRY\nQ09YDV3UTxquYav6vfDCC9pvv/2c1K/K+OA/AACALjQwMLDVbrCwa+RqnauTa2XK1SwPOwfhWpav\nNXpQeXLRgwCgvFhkBgAAAAAAAADEVqvX65EfZIyZKuk2SU8PXVoh6buSFkkaKemPkk631m4MDeAl\nr9Xq9XpdtVot8hySIi95yeskb/ZJ5a4HSYreAAEUSS49yJFc+k+zD1Jqdw5mnB1knZxP2jiHuDvV\nouQK5swiTxlzpfWaqJgy9x+pID2ok9ead7+kudrFpwcVJxc9qCP0oIhWrVrlj0899VRJ0p/+9Cf/\n2vTp0/3xs88+64/vvffeWPmOO+443XvvvTruuOO2OIbhjjvu8Mc77bSTP7711lv98YQJEzrO893v\nftcfv/baa/742muv9cfnnHOOP95xxx398de+9rWO84TVTxqs4bp16zRu3Di/hi7qJw3W0OPV0HX9\npOEatqpff3+/+vr6YtevgkJ7UJIzmf+vtfZk7y/GmAWSrrbW3maMmSfpLEnXJIifuXnzxodenzt3\nrdP4jXlcx29UlvhZ5MjiOSAzletBaX9qd7NP63YZP0xZ4meRI8tPgQdaaewF3muw8UOV4i4yNMsV\nfK27/gCnZs+h8Zqr5+TFbZx/8FoZc3XytXKRC90ty9caPahcuehBAFBeLj/4b6ok70TvuyTNUYkW\neJotPgZvS7IQWYT4SeQ5f+/2IsdHIUxViXtQq2+WXfwQlHf8pD/A5Tl/7/YixwcAAADQ3MMPP+yP\n77//fknSCy+84F+77777/PHpp5+eON/FF1/s//nQQw/51++++25/HPywvLvuussfR9mJ+6Mf/cgf\nf/GLX/THy5cv98c/+9nP/PF1113nj6PsxA2rnzRcw7vvvtuvoYv6ScM1lOTX0HX9pOEatqvf2LFj\nY9evWyRZZD7QGHOnpF5JF0vqCbw1/WVJu7ULsGLFCkmDb/XPQ9S8fX1u8vb1PZ9q/GbSrnOz+bvK\nG7U+eX19y/J6roDEPahI0l5gDMbP6kNaiJ9dfCCONHf0NcsVtnu67LnSendIXrmyrB+6W5X7Qpa5\n6EEAgKKIu8j8jAYXdW6V9EFJ9zfE6uh8oEmTJhXmDNvgTtbgrte5c9c626k7d+5a1et19ffvmVp8\nb9wYv6/v+UR1jlufTr++wRiN8RvzdyLs6+syfqd5s5Jn3pw46UFF0uzths3eNli2+C52Mqc9/8Z4\nwZiudjKnFR8AAAAAgDzFWmS21v5B0i1Df/2dMeZFSR83xoy21q6XtLukdY7mmKrggmPYkQqNt0dd\niCR+shxht7l8Di7iI3tV6kHBBcewIxUab4+6ENnu8a7jR82fd/x2OcJuc/kcXMQHAAAA0LmxY8dK\nkg477DD/2sKFC1PLF8xzyimn+OPVq1c7zTNnzhx/3OzdAMHjHuLy6icNPrfVq1frlFNOyaSGedZv\nzpw5TupXZbEWmY0xMyXtZq293Bizq6RdJC2QNEPSTUN/3uNslgAQQA8CgOSCv9ho9YFVrnO1ulbG\nXK0+CKuMubyYWR6ngu6U5WuNHlSeXPQgACivETEfd6eko4wxD0i6Q9I/S7pI0hlD13ol/djNFLMR\n3L06d+5a/7/g38scP6ks5t8YrzFnkeMjc5XrQY1nJge/uW78RruM8ZPKYv6N8VyeY512fAAAAAAA\n8hT3uIy/Svq7kJuOSzadfDU7c9hl/L6+dONL5Y3vxStzfGSjqj0o7Q86IX5nOcocH9kwxkyVdJuk\np4curZD0XUmLJI2U9EdJpwc+jBQAnKD/AEBya9cOrgM8+eST/rWLL77YH//d34X9qBnfXXfd5Y+D\nOb15uBI8SiL4c0bwugvBeXvP58knn/Rr6Lp+0nAN86rfbbfd5ryOVRR3JzMAAEA3+7/W2qlD/31Z\n0iWSrrbWHinpWUln5Ts9ABVG/wEAAIXDIjMAAEByUzV4lI8k3SXp2PymAqDLTBX9BwAA5CzWcRlV\n5R2jEDxCYd688c6OVCB+Zzka4zfmLHJ8IIlmHxTj6kiFZh+k4jK+lO7804wfFs/1B82kHR+ZOtAY\nc6cGz4C/WFJP4O3pL0vaLbeZtdDuLPDGa0lem0XN5SpPVXOl/bWCE6XsP1Jx+0KWucrYF7LMRQ9C\nWg499FB//P73v1+SNHLkSP/a9OnT/fGee+6ZON/ee+/t/xmMHczpzaNxflFceOGF/niXXXYJvc8Z\nZ5zhj1966aVYecLqJw0/n5EjR/rP00X9pOEaSsNfH9f1k4Zr2K5+Z5xxRuz6dQsWmQEAAKJ5RoML\nO7dK+qCk+7Xl91S1PCYFoCvQfwAAQCGxyAwAABCBtfYPkm4Z+uvvjDEvSvq4MWa0tXa9pN0lrctt\nggAqi/4DAACKikVmAACACIwxMyXtZq293Bizq6RdJC2QNEPSTUN/3pPjFAFUFP0HAOKZMGFCy9uT\nHLcQZty4cf6f3rjRNtts44/f9773xcpz9tlnt73P3/7t38aKHdSufttss01qNWwcB3N64tZPal9D\nr34u6lh1LDIDAABEc6eknxhjpkt6j6R/lvS4pBuNMedIek7Sj3OcH4Dqov8AAIBCqtXr9fyS12r1\ner2uWi37o8PIS17yOslb9nP/8muAAFwocw+i/wDlVub+I9GDgLKjBwHIU2gPGpH1LAAAAAAAAAAA\n1cEiMwAAAAAAAAAgNhaZAQAAAAAAAACxscgMAAAAAAAAAIiNRWYAAAAAAAAAQGwsMgMAAAAAAAAA\nYmORGQAAAAAAAAAQG4vMAADQLnyaAAAgAElEQVQAAAAAAIDYRuU9AQAAAGSjt7dXkjQwMJDK/ZPm\nipMn6mOzfk5VzRX3a4XuVtXXNT2oPF8rdK+FCxf641mzZrW87/Lly/3x4YcfHivf8uXLdfjhh/t/\nupxf0AEHHOCPV69e7fz+nqzrFzVO3PpJwzVJs37dgp3MAAAAAAAAAIDYWGQGAAAAAAAAAMTW9cdl\nzJs3XpI0d+7aju7byf2IH02nj4sylyzjA0lEeXtgnLcGEr+zHJ3G73QuWcYH4gp7zaX1OqxyrsaY\nab2NO6tczfJI9Ce4leVrjR5Unlz0IGThpZdekiTtsMMO/rUFCxb44w9/+MNO882fP98fn3nmmf74\nz3/+s9M8fX19/ri/vz/0ugte/aTBGm677bbauHGjX0PX9ZOGa5hX/fr7+53XsYrYyQwAAAAAAAAA\niK3rdzIDAAB0O2+XWFXyZJmris8p61zoblV9XdODypMLAOAGi8wBYcclxD0ColX8xmuu46c9/7Ti\nh8VzfYRF2vGBJJq9vdLVWwPTfptjFvNPM35YPNdvz0w7PtCO91pr9m8neHvw765yBRcNGm9Pmqtx\nzq1yJckTjB3M22ouZcqV9usC3Y0eRA9ql4sehLRMmzbNH//0pz+VJF166aX+tZkzZ/rjUaOGl8oO\nP/zwWPlWrlypww8/XCtXrtSaNWv86/vuu68//vrXv+6Pjz/++Fh5LrvsMn+8efNmfxz893r11Vf7\n44MPPjhWnrD6SYM1fOGFF7Tvvvv6NXRRP2mwhh6vhq7rJw3XsF39PvzhD8euX7dgkTlE2GIw8YkP\nZCXtnRvEr3Z8AAAAAACyxiIzAABAl2m3C8zlLrGscnUSJ6tcZaxf1rnQ3ar4uqYHlSsXAMC9Wr1e\nzy95rVav1+uq1WqZ527MGzxGIbjTde7ctU6OVPDi1+t19ffvmVp8b9wYv6/v+UR1jlufTr++wRiN\n8RvzdyLs6+syfqd5s5Jj3uyTupVfA2zQ6q2cLt4amHf8pD8UZDH/xnjBmEmfQ9rxu1iZe1Bh+o+U\n3VuQw17/Zc8V9vbxquWiP4Uqc/+RCtSDqtgXssxFD+pa9CAHDjjgAH+8cOFCf5zkiIcwy5cv98ez\nZs3yx6tXr3aaJyirf0MHHHCAVq9erQMOOMCvoev6ScM1rFr9Siy0B7GTeUirBUYXi495x+/rSzd+\nUu1iJM2RdnwgqVb/43LxPzXix4/vIgc7cwAAAAAAVTYi7wkAAAAAAAAAAMqLRWYAAAAAAAAAQGyx\njsswxpwt6fTApY9J+m9JPZLeHLr2P6y1jyabHgBsjR4EAMkFz2FuPPPc9REuYXGrkqsxZlpnrGeV\ny4uZRf3Q3bJ8rdGDypOLHgQA5RVrkdlae72k6yXJGHOUpFMlHSTpTGvtU+6mBwBbowcBAAAAAAAU\nh4sP/vumpJmSFjuIlat588ZL2vJD4ObNG+/sQ+GI31mOxviNOYscH7moTA9qtvPF1a6NZjtDXMaX\n0p1/mvHD4rneOZN2fKCddp+U3bijudV9XeYaGBhI9O85zvNK+pxa5XJdvyxzpVk/gB5ED2qXix6E\ntDz44IP++J577pEkrVq1yr/2yiuv+OOzzz7bH19//fWx8p199tm6/vrrdfbZZ2vevHn+9WDOb3zj\nG/7405/+tD+eMmVKpDyeWbNm+ePgv5EHHnjAHy9cuNAfR3luYfWThp/PqlWr/Bq6qF9jHK+GrusX\nzNOqfkceeaQeeOCB2PXrFokWmY0xH5e01lr7ojFGki4xxuwk6beSvmqtXd/q8StWrJAk1ev1JNOI\nrVnevr7Wf3ed13X8ZvN3Veeo9YmaNyxenBp1+vWNGz9q3rTllTdPSXtQ0bT6ppr46ccPi1e2+EA7\nnb7mXLw2o+ZKkjOr51Xk+pUlF7pbkV/X9KDuyAU3jDGjJT0l6X9KWippkaSRkv4o6XRr7cYcpwcg\nJ0l3Mn9B0sKh8Q8kPWmt/Z0x5hpJ50u6vNWDJ02apHq9rlqtlnAa0Xl5vZ2sUvPdrJ3cp5nGx4Y9\nX5fxm92nr+959ffvmVr8Zvfp5OubxtcgmDftr3GzvFnKM2/OEvWgIuhkR0aSXRtFiR93h1Da888i\nRxbPAQAAAMjQ1yV537ReIulqa+1txph5ks6SdE1uMwOQm1qSRSJjjJU0yVr7dsP1EyR9xlp7Rsvk\ntVq9GxflyEveCuXNPmlA0h4kKfdVcgCJ5NqDEqL/AOVW5v4j0YOAssutBxljJkjql/SEpN9L+pak\nCdbajcaYwyTNsdbOaBOGHgSUW2gPGhE3mjFmnKQ3rLVvG2Nqxpj7jDE7DN08VYNvnQCAVNCDAAAA\nACBz35c0O/D3nsDxGC9L2i37KQEogtiLzBpsHC9LkrW2Luk6SUuNMcskjZd0dfLpAUBT9CAAAAAA\nyIgx5vOSHrLWrmlyl7K/ywNAAomOy0icnOMyyEvesuct+zcRvE0LKLcy9yD6D1BuZe4/Ej0IKLtc\nepAx5hZJH5T0jqQ9JG0cmstB1tr1xpijJH3ZWntym1D0IKDcQntQ0g/+AwAAAAAAQMVZaz/jjY0x\n39bgmcyHS5oh6aahP+/JY24A8pfkuAwAAAAAAAB0r29JOsMY84CkXkk/znk+AHLCcRnkJS95k+Tl\nraIA8pTXW0XPlnR64NLHJP23pB5Jbw5d+x/W2kdbhKH/AOVW5v4j0YOAsuPnMAB5Cu1BLDKTl7zk\nTZKXb24A5Cn3HjR09uCpkg6S9CVr7VMdPpT+A5RbmfuPRA8Cyi73HpQQPQgot9AexHEZAAAA8X1T\n0v/MexIAuhL9BwAAFAaLzAAAADEYYz4uaa219sWhS5cYY5YZY641xozOc24Aqo3+AwAAioZFZgAA\ngHi+IGnh0PgHkv7VWvtJSe9KOj+vSQHoCvQfAABQKKPyngAAAEBJTZX0ZUmy1v40cP0uSZ/JY0IA\nusZU0X8AIJb169dLkh577LHQ26dMmeI034MPPhh6/eCDD/bHo0cnfxPKypUr/fFrr73mj3fccUd/\nfOCBBybO49VPGqzhlClTtniOrusnhdcwy/odeOCBWrlypZP6VRmLzAHz5o0PvT537lqn8RvzuI7f\nqCzxs8iRxXMA4urt7Q29PjAw4Cz+wMDAVnlcxg9TlvhZ5MjiOSAbxphxkt6w1r5tjKlJulfSydba\nP2tw8SfKB3Dlwns9ptkXGnOFqWKuNP5NZ5Wr2f8r0siFeKrQf6RsX2tF6AtZ5qIHAQDywHEZQ5ot\nPnq3tbq9DPGTymL+aT6HtOMDSbX6gaS3t7fl7WWIn1QW80/zOaQdH7nYTdLLkmStrUu6TtJSY8wy\nSeMlXZ3j3ABUG/0HAAAUDjuZAQAAIrLWPirp+MDfb5V0a34ziqbdLzaCu5yzyJVFnixzZV2/MuZC\nfGXvP1LxXtf0oO7Lhe6zadMmf7z77rtLknbddVf/2oYNG/zx9OnT/fGVV14ZK98FF1ygK6+8Uhdc\ncIFuueUW//rGjRv98ahRw0tyL7zwgj/eZpttOs7z6quv+uMjjjjCH7/3ve/1x9tuu60/fuihh/zx\n2LFjO84TVj9psIYrV67UP/3TP/k1dFE/abCGHq+GrusnDdewVf1Wr16tv//7v49dv27R9TuZw3a4\nBo9OCI7j7HYlfmc5GuN7cYPjuDum044PJBG2wzX4jXNwHGe3K/E7y9EY34sbHMfdMZ12fCCKZq+z\nsNdkq/vHzdXs9e/dP652b6t29W+t3XNqzFuVXC6/VuhucV5rZXhd04PK87UCAKSn63cyBxcYPc3G\ncc7tJX5nOcocH0gi+AOHp9k4zq4N4neWo8zxAQAAAADIW9cvMgMAAHSLsF/cBP/e6p0DLnI1G7vI\n1ew5NY7TfE5VzeXya4XulnVfyDIXPagcXyt0r+BxD5499tjDH7/22mv+OHh0RlxejA0bNmj06NGh\n8wge69Dsejuvv/566PUxY8b44+CxDsH7xz0uI8ir4R577OHX0EX9GuN4NXRdPym8hmH123XXXWPX\nr1t0/XEZnla7WINHKpQ1flJZzD/N55B2fCCpVt8sN75FsIzxk8pi/mk+h7TjAwAAAACQJ3Yyh3Bx\nzjDxuzc+kFTaZ84Rv9rxgU6E7bprvL1suZrt0s4jl+v6ZZkrq9cFuhs9KN1c9CAAQB5YZAYAAOhy\nnSyOuMxTpVyNix5VzMUvxJCmKvaFLHPRg4DObL/99v74iSeekCTdf//9/rUlS5b442uuuSZxPi/G\nNddco+nTp/vXZ8yY4Y+nTZsWOr8oPvjBD/rjY445xh+fdtpp/njx4sWh948irH7ScA0/97nP+TV0\nUb/GOF4NXddPGq5Ju/rtsssusevXLTguAwAAAAAAAAAQGzuZh8ybNz70XN65c9f6RyokObfXi9/X\nl278RsH4SWRRn7AY3t+b5S9KfCCp3t7e0LcABt82mOQtgnnHT/r2xizmHxYjuLuzyPEBAAAAdOb3\nv/+9pC13q2677bb++KWXXvLHu+yyS6wcL730knbZZRe99NJL+uxnP+tfP+mkk/zxr371K388fny8\ndZt3333XH0+YMMEfB3f8/uY3vwm9/4gR8fadevWThmt42mmn+TV0Ub/GOF4NXddPGq5Ju/pNmDDB\nSf2qjIoAAAAAAAAAAGJjJzMAAECXafXuAO/24N/TzuUqTzBunrlc1y/LXFm9LtDd6EHp5qIHAQDy\nUKvX6/klr9Xq9XpdtVot89xe3ihHPcQ5UqExfqvn6yJ+M/V6Xf39e6YW37tv4/06+fp2+ryjzCWY\nN434neTNUo55s0/qVn4NcEiUb5bj/GBC/M5ydBq/07lkGb/LlbkH5dp/2r0us1g06PT2KHmk1nPO\nKldWCzxp5MrqdVEBZe4/Ej2o49uj5JHoQUlz0YM6Rg9K4JRTTpEk3XbbbaG39wXOOe3v74+Vo6+v\nT/39/f6frebRai7tbNiwwR+/8sor/jh4fMTatcNrHDvvvLM/3m677WLlbDdvF/XrJI6L+knDNWxV\nv/Hjx2vt2rVO6lcRoT2I4zIAAAAAAAAAALF1/XEZUXatxtnhSnx3jytqfCCJKDsx4uzaIL67xxU1\nPhBFp7vAXLw1OU6uuP8OOn1s0rd2F71+WeaiZyGOqr6u6UHl+VoBANLT9cdlkJe85E2Ul7dpAchT\nmXtQLv0n6iJAFosGwfunvcATZ15JHlvlXCzwlLr/SPSg0PvTg8qTix5ED4rqz3/+sz/eYYcdWt73\nzTff9Mc9PT2x8r355pvq6enx/3Q5v6BnnnnGH++///7O7+/Jun5R48StnzRckzTrV0GhPajrdzID\nAAB0i6g/lCf5Ib6ouar4nMqUC92tqq9relB5cgEA0sOZzAAAAAAAAACA2Dgug7zkJW+SvLxNC0Ce\nytyD6D9AuZW5/0j0IKDs6EEA8hT/uAxjzERJd0i60lr7Q2PMeEmLJI2U9EdJp1trNxpjZkr6qqR3\nJV1nrb3eydQBdDV6EAAAAAAAQHG1PS7DGNMj6SpJSwOXL5F0tbX2SEnPSjpr6H7flHSspKmSLjDG\n9DqfMYCuQg8CAAAAAAAotk7OZN4o6QRJ6wLXpkq6c2h8lwYXdQ6R9Ii19nVr7XpJD0qa4m6qALoU\nPQgAAAAAAKDA2h6XYa3dLGmzMSZ4ucdau3Fo/LKk3STtKumVwH28602tWLFC0uB5snkgL3nJW3xp\n9iAAAAAAAAAk19GZzG00O3C+7UH0kyZN6sYPSiMveSuVtwBi9yAAAAAAAAAk18lxGWHeMMaMHhrv\nrsG3sa/T4E5CNVwHANfoQQAAAAAAAAURd5H5PkkzhsYzJN0j6VeSPm6M2cEYM0aDZ6E+kHyKALAV\nehAAAAAAAEBB1Nq93d0YM1nS9yXtLWmTpD9ImilpoaTtJD0n6Uxr7SZjzMmS/lVSXdJV1tqbWyav\n1epFOl5g3rzxofedO3etk5zz5o1XX9/z6u/fM7X4YebOXevkOIU49Yma19XXoFnetL/GRXo9Z5Q3\n9aRp9qCh+xVGb29v6PWBgQFn8QcGBrbK4zJ+mLLEzyJHFs+hy5T5WJxC9R8AkZW5/0j0IKDs6EEA\n8hTag9ouMqepSIvMzRYfg5IsRHrxwxaZXcZvpq/v+UR1jlufTr++ruuf9de3Wd6sVHmROWWF+eam\n2eJjUJKFSC9+2CKzy/jNJF1Ezao+ZY3fxcrcgwrTfwDEUub+I9GDgLKjBwHIU2gPintcBgAAAAAA\nAAAA7GTu5PiE4H2i7nZtjO/tZE4rflic4DEdacUPuy51tsM2ja9BMG/aX+NmebPETubYcv8Neie7\nioP3ibrbNexoDO/YjDTih8UJHtORVvyw60XJkcVz6GJl7kGF6T9pHqPTmCtMFXOl8e84q1zNjlZK\nI1fJlbn/SAXpQVm91orQF7LMRQ/qCvSgBBYuXChJmj17dujtjz76qD/eZ599YuVYs2aN9tlnH61Z\ns0aTJ08Ovc8VV1zhj2fNmhUrzzvvvOOPP/nJT/rj3/72t/74Qx/6kD9etmyZPx45cmSsnF79pMEa\nNv6bdVE/abCGnrAauqifNFzDVvV78MEHNWXKFCf1qwh2MgMAAAAAAAAA3BqV9wQAAACQrXbnhAd3\nOWeRK4s8WebKun5lzIXuVrTXNT2o+3IBANxjkbmJTj4ojvjpqsJzAOLq5AcV4qerCs8BaNTp27i9\n+yX5gT5OrrgLB52+jbu3tzfz51TVXCzyII6qvq7pQeX5WqF7NR7x0Mj1UXaTJ0/WwMDAVsc8BOOd\ncsopoY+NcvTDzjvvHHo9eJTEMcccE3r/KM+tXf2C8VwdBRh2RIbr+knhNQyr3+LFi2PXr1twXAYA\nAAAAAAAAILau38nsfcjbvHnjtxiH3cdF/L6+5vdxEd8bN96nry9enrTr4z3eixkcu8qRdnwgieBv\ne8N+8xu8j6v4ze7jKn6z+cfJk3Z9vMe3+gC0pDnSjg8AAAAAQN66fpE5THDBMY0jFYhf7fhAUs3e\nqkV84iN7xpiJku6QdKW19ofGmPGSFkkaKemPkk631m40xsyU9FVJ70q6zlp7fW6TBlAZ9CAAyMYJ\nJ5yQeZ4nn3zSH5944olO83zve9/zxzfccIPT2M1kUcO86rds2TLNnDnTaY4qYpEZAAAghDGmR9JV\nkpYGLl8i6Wpr7W3GmHmSzjLG3Cjpm5I+IeltSY8YY35qrS3VFvUsf+mRVa4qPqcq58KW6EHlz1XF\n51TlXACAZFhkBgAACLdR0gmSLgxcmyrp3KHxXZLmSLKSHrHWvi5JxpgHJU0Zur1QOjlCJ3g/17la\nHRfj8liadrmS5AnGTvMInLxypf26QCT0IMe56EHFz0UPAoDyYpEZAAAghLV2s6TNxpjg5R5r7cah\n8cuSdpO0q6RXAvfxrhdW4w/qaf7gHoydVZ4sc6W96FHVXGivW3pQVV7X9KBy5UL3mTVrlj/++c9/\nLkk666yz/Gvz58/3xy5ef+ecc47/5+zZs/3rd999tz++9tpr/fH48fGO8ly3bp0/fuWV4f8V/PrX\nv/bHixcv9sfLli2LlSesftJwDW+++Wa/hq7+/Xo1lOTX0HX9pOEatqvfLrvsErt+3WJE3hMAAAAo\nqVrE64XR7O3Hvb29zt+anFWuVvGyzuVS1rmizgG5ogcVKBc9yE2uqHMAABQHO5kDgh8C1+zD4YLX\n48afN298qvEb4zTL6zp+4/Ui5sjiOQBxBb95bvbhcEl+K+y9BbHxrYgu44fFaZbXZfyw60XMkcVz\nQOreMMaMttaul7S7pHVD/+0auM/ukh7OY3IAKo8eBAAAColF5iHNFhZdLTh6cfr6tozpOn6neV3H\nT6rs8YGkmi0sulpwbPb2wzTid5I3jfhJlD0+MnWfpBmSbhr68x5Jv5L0I2PMDpI2a/As1K/mNkMA\nVUYPAgBHjj/+eH+c5jEIO++8sz8+9dRT/XHweAbXZsyY4Y+Dx2W45tXw+OOPz6SGVatf1bDIDAAA\nEMIYM1nS9yXtLWmTMeZkSTMlLTTGnCPpOUk/ttZuMsb8m6T/kFSXdLH3AVwAEBc9CEARGWNmSvqa\nBn+p9U1JT0paJGmkpD9KOj1wdjyALsIiMwAAQAhr7aOSpobcdFzIfW+XdHvacwLQPehBAIrGGDNW\n0rckTZY0RtLFkk6WdLW19jZjzDxJZ0m6Jr9ZAsgLi8wAAABdyDsLvN1Z7d59XOQKi+fq3PawXI3x\nXJ9/3sk562XLFfx6tMrFcT9IqtPXWuNtcXM1i0cPKlYuelDhHSvpPmvtXyX9VdIXjTFrJJ07dPtd\nkuao4IvMS5culbTla+qcc87xx2n+W123bp0//shHPuKPr7jiCn88a9asWHmaxfOeb+Nc4j63xnje\nv1mvhmn8W/Vi5lm/pUuX0ofaYJEZAAAAAAAA7ewtaXtjzJ2SdpT0bUk9geMxXpa0Wz5T61y7xcH+\n/v7EObwY/f39TeO5WKTcbrvt2saLu+jaTFie4DUX9WuMExbT1SKvV8N29WNRub1avV7PL3mtVq/X\n66rVapnnJi95yeskb/ZJ3cqvAQJwocw9iP4DlFuZ+49EDwLKLpceNHT++xRJJ0naS9L9kkZba3ce\nun0/STdaaw9vEyrXHtS4A1/acifztdde64/jLiz29fWpv79ffX19W8QL7sQdN26cP467E3fDhg1t\n482ePTv0sXGfW9g7GII7mV3UTxqsoceL6bp+0nANW9Uv+A4LT5cvOof2IBaZyUte8ibJyw9YAPJU\n5h5E/wHKrcz9R6IHAWWX1yLzmZJ2tdb2D/39aUmjJR1krV1vjDlK0pettSe3CUUPAsottAeNyHoW\nAAAAAAAAKJ3/lHS0MWbE0IcAjpF0n6QZQ7fPkHRPXpMDkC92MpOXvORNkpddPADyVOYeRP8Byq3M\n/UeiBwFll1sPMsacI+nsob9eKukRSTdK2k7Sc5LOtNZuahOGHgSUG8dlBJGXvOR1kpcfsADkqcw9\niP4DlFuZ+49EDwLKjh4EIE8clwEAAAAAAAAAcItFZgAAAAAAAABAbKPynkARzZs33h/PnbuW+MQH\nMtXb2+uPBwYGiE98AAAAAAAKjZ3MAAAAAAAAAIDYWGQeEtzdGnZbq9vLED+pLOaf5nNIOz6QVHB3\na9htrW4vQ/yksph/ms8h7fgAAAAAAOSp6xeZoyyQxlmIJL67x8VdzE47PpBElAXSOAuRxHf3uLiL\n2WnHBwAAAAAgbx2dyWyMmSjpDklXWmt/aIwZL2mBpG0kbZL0OWvti8aYTZIeDDz0GGvtO64nDaC7\n0IMAAAAAAACKq+0iszGmR9JVkpYGLl8q6Tpr7a3GmPMlzZb0NUmvW2unpjHRLITtYnW5s5X40XOU\nLT7c66YeFLaL1eXO1t7e3q0+aM51/E6uFTV+WLyyxQcAAADQmf7+fn/82c9+1h/vtddeTvM899xz\n/vgnP/mJP+7r63OaJ+iiiy7yx5dddllqefr7+9XX16f+/n6/hq7rJw3XsGr1q5pOdjJvlHSCpAsD\n186TtGFo/Iqkgx3PKzNz566VNLjY6I0beQuRzW6PEr+vb+s4LuOHKXJ873HtYrTKn3d8pK7SPchb\n9A1bAPZ4C5HNbo8av9lCs6v4jYoc33tcuxit8ucdH3Ah6b+jqHmqlKvxl0VVzEV/Qpqq2BeyzEUP\nAgAURdtFZmvtZkmbjTHBa29KkjFmpKTzJV0ydNN2xpifSNpL0hJr7RWtYq9YsUKSVK/X48w9sca8\n7X4JkvSXJN7jmz1fV/GbSVrnuPWJkrdVjqj1CcvrMn6UvFnIK2/a0uxBRdLqm2cX31gTP358FznS\njg8AAAAAQJ46OpM5zNDiziJJv7DWem9jnyPpJkl1ScuMMcustf/dLMakSZNUr9dVq9XiTiO2xrxp\n7tQNxg97vi7jN7utr+/5RHWOW59Ov76udxqHfX1dxu80b1byzJsXFz2oSNLcqVuE+EkXUbOYf6sY\nSZ8DO5lRNO1ecy53NneSy1UeqfWcs8rlun5Z5srqdYHuRg9KNxc9CNjaiy++6I+//OUvS5KeeOIJ\n/9pRRx3ljy+8cPhNtIsXL46V77TTTtPixYt12mmn6V/+5V/86wsWLPDHjz32mD++6qqr/PGuu+7a\ncZ57773XH0+YMMEfX3PNNf743HPP9cerVq3yx8cdd1zHecLqJw3WsK+vTwsWLPBr6KJ+0mANPV4N\nXddPGq5hq/qNHz9ea9eujV2/bhF7kVmDH7r1jLX2Yu+CtXa+NzbGLJU0SVIpFniaSfsYhazip3VU\nTRbzl5ItwOcZH6nqih6U9uIj8dvHl9L7YYYflpC1qOeAJ3mNxskV999ClFxZP6eq5qJvIY6qvq7p\nQeX5WgEA0hNrkdkYM1PS29babwWuGUnfkjRT0khJUyTd7mKSABBEDwIAAAAAACiOWru3uxtjJkv6\nvqS9JW2S9AdJH9Dgh279ZehuK6215xljviPpaEnvSrrTWtvyIxhrtVo97+MFmu1kdbXDtTFOu7xJ\n47fLm1b8ZjrJ22w3dJJd0sG8acTvJG+WcsybetI0e5AGj9XIVbNdH652uBK/sxxhcVy+pTXN+F0u\n+8bnTi79J2y3WPDDKZtJe2eaN4csdhEGc2aRp4y50npNVEyZ+49UkB7UyWvNu1/SXO3i04OKk4se\n1BF6UERLlizxx+edd54kaaeddgq972uvveaP161bFyvfuHHjtG7dOo0bN0477rhj6H3+9Kc/+eN/\n//d/98czZszoOM+BBx7ojzdv3uyPt9lmG3+8adMmfzxq1PBe05UrV3acJ6x+0mANn376aR100EH+\nNRf1kwZr6AmroYv6ScM1bFW/1atX64ADDohdvwoK7UGdfPDfo5KmdpLBWnth+3sBQOfoQQAAAAAA\nAMWW5ExmAAAAlIi386txx14a7xZolquRq1xZfOhW8Dm1yuW6flnm8sbN3oGRNBe6W5avNXoQPQgA\nkC0WmUNU5cP+yhxf4vLoJsYAACAASURBVMP+0L2q8GF5ZY8v8WF/AAAAQFUEj1BYvHixJOm2224L\nvW9fX1/ifGeccYb/Z39/f+h9TjnllND5RfHYY4/541deecUfjx8/3h+vXTu89rHzzjvHyhNWP2m4\nhk8//bR/zUX9pOEaSgqtoYv6ScM1bFe/pUuXxq5ft+j6ReawhUaXi4/Ej56jbPGBJMIWGl0uPhI/\neo6yxQcAAAAAIG9dv8gMAACAQVnutK9yrqx+mZRVLt6BgaxUuS9kmYseBADIA4vMAAAAAAAAqKxV\nq1b54wsuuGCr2xctWuSPmx1vEcWBBx64xZ+eq6++2h8vXLgwcZ7rr7/eH8+aNcsfB59v8Bc0wWMg\nomhXP2m4hi7qJ21dO8l9/aThGraq3/jx47V27drY9esWLDIDAAB0iVa7wVzvSMs6VxYfEtXuOVU1\nF7sH4Qo9KHmeZvGqnIseBADlwCIzAAAAAAAAKuvhhx/2x96O1Weeeca/duihhzrNt++++/p/vvnm\nm/71Z5991h/39PQkzvODH/zAH59//vn+OOz5JtEs3jPPPKP9999fzzzzTGo1lOTX0HX9pOEatqvf\n4Ycf7iRflY3IewIAAAAAAAAAgPJiJzMAAECXq+KHN1X1OVUxF7pbVV/X9KDy5AIAuFGr1+v5Ja/V\n6vV6XbVaLfPc5CUveZ3kzT6pW/k1QAAulLkH5dJ/mv3QnsZiSFiutBYNwuZfhedUxVwVUub+IxWo\nB1XhdU0PKk+uCqEHAchTaA9ikZm85CVvkrx8cwMgT2XuQfQfoNzK3H8kehBQdvQgAHkK7UEclwEA\nANCEMWaipDskXWmt/aExZrykBZK2kbRJ0uestS8aYzZJejDw0GOste9kP2MAVUIPAgAAZcEiMwAA\nQAhjTI+kqyQtDVy+VNJ11tpbjTHnS5ot6WuSXrfWTs1+lgCqih4EAADKZETeEwAAACiojZJOkLQu\ncO08SUuGxq9IGpv1pAB0DXoQAAAoDXYyAwAAhLDWbpa02RgTvPamJBljRko6X9IlQzdtZ4z5iaS9\nJC2x1l6R8XQBVAw9CAAAlAk7mQEAACIYWtxZJOkX1lrvbexzJH1R0qckzTTGfCyv+QGoNnoQAAAo\nInYyAwAARLNA0jPW2ou9C9ba+d7YGLNU0iRJ/53D3ABUHz0IAAAUDovMAAAAHTLGzJT0trX2W4Fr\nRtK3JM2UNFLSFEm35zNDAFVGDwIAAEVVq9fr+SWv1er1el21Wi3z3OQlL3md5M0+qVv5NUAALqTa\ng4wxkyV9X9LekjZJ+oOkD0jaIOkvQ3dbaa09zxjzHUlHS3pX0p3W2svahKf/AOWW+vdA9CAALfBz\nGIA8hfYgFpnJS17yJsnLNzcA8lTmHkT/AcqtzP1HogcBZUcPApCn0B7EB/8BAAAAAAAAAGJjkRkA\nAAAAAAAAEBuLzAAAAAAAAACA2FhkBgAAAAAAAADExiIzAAAAAAAAACA2FpkBAAAAAAAAALGxyAwA\nAAAAAAAAiI1FZgAAAAAAAABAbKM6uZMxZqKkOyRdaa39oTFmoaTJkl4dusv3rLU/N8bMlPRVSe9K\nus5ae30KcwbQZehBAAAAAAAAxdV2kdkY0yPpKklLG27qs9b+rOF+35T0CUlvS3rEGPNTa+2Aw/kC\n6DL0IAAAAAAAgGLr5LiMjZJOkLSuzf0OkfSItfZ1a+16SQ9KmpJwfgBADwIAAAAAACiwtjuZrbWb\nJW02xjTe9CVjzGxJL0v6kqRdJb0SuP1lSbs5mieALkUPAgAAAAAAKLaOzmQOsUjSq9ba3xhj/k3S\ntyUtb7hPrV2QFStWSJLq9XrMaSRDXvKSt7Sc9CAAAAAAAAAkF2uR2VobPBv1TknXSLpdgzsJPbtL\nerhVnEmTJqler6tWy34tiLzkJa+bvHlw1YMAAAAAAJ0xxoyRdKOkHSVtK+liSS9q8OexuqQnrbX/\nnN8MAeSpkzOZt2KMWWKM+eDQX6dKekrSryR93Bizw1DjmSLpASezBIAAehAAAAAAZG6WJGutnSbp\nZEk/kPS/JH3FWjtF0vuNMcfnOD8AOWq7k9kYM1nS9yXtLWmTMeZkSVdJusUY85akNySdaa1dP/S2\n9f/Q4G+wLrbWvp7azAF0BXoQAAAAABTCnyR9eGi8o6QBSftYax8ZunaXpGMl3Z3D3ADkrJbnOa61\nWq3ejccLkJe8Fcpb9nOPu+oga6CCytyD6D9AuZW5/0j0IKDscutBxph7JO2nwUXmv5N0tbX2o0O3\nHSPpbGvtZ9uEoQcB5Rbag2IdlwEAAAAAAIDuYYz5nKTnrbX7STpa0k0Ndyn7L+AAJMAiMwAAAAAA\nANqZosHjCWWtfULSaEk7BW7fXdK6HOYFoABYZAYAAAAAAEA7z0o6RJKMMXtJ+quk3xpjjhi6/R8k\n3ZPT3ADkjDOZyUte8ibJW/a3Q3EWGFBuZe5B9B+g3MrcfyR6EFB2ufQgY8wYSTdI2kXSKEnfkPSi\npGs1uInxV9ba2R2EogcB5Rbag1hkLkDen8+YEHrfE5esSjWvK63mX6Q6t+Lqa1CW5+swLz9gVcCM\nGTNCry9ZsiTjmcRT9vlL1XgOOSlzD6L/AOVW5v4j0YOAsqMHAcgTH/wHAAAAAAAAAHCLRWYAAAAA\nAAAAQGwcl5Fz3mbHNAS5ODYjrefbbv4n3P7bQtS5Gdf1L8rrKsO8vE2r5Jod0xBU5CMb2s2/yHOX\nyl//AihzD+r6/gOUXJn7j0QPAsqOHgQgTxyXAQAAAAAAAABwi0VmAAAAAAAAAEBsLDIDAAAAAAAA\nAGJjkRkAAAAAAAAAEBuLzAAAAAAAAACA2FhkBgAAAAAAAADExiIzAAAAAAAAACC2UXlPAAAAAAAA\nAOgml19+uT9etWqVP54wYYI/njNnTqZzcuELX/hC6PXvfOc7/njs2LFZTSexV199VWPHjtWrr76q\nCy+8MPQ+P/rRjzKeVTGxyAwAANCEMWaipDskXWmt/aExZqGkyZJeHbrL96y1PzfGzJT0VUnvSrrO\nWnt9LhMuoRkzZmjJkiWaMWPGVrctWbIkhxklF/ZcPGV9TlJ1n1eR0YPSRw8qj6o+LwCoChaZAQAA\nQhhjeiRdJWlpw0191tqfNdzvm5I+IeltSY8YY35qrR3IbLIAKoceBAAAyoRFZgAAgHAbJZ0gKfx9\nccMOkfSItfZ1STLGPChpiqS70p0egIqjBwFAxWzevNkfP/300/74L3/5S+h17/6jRhV/+e7RRx+V\nJL322muhty9YsMAfl+kYkAULFmjOnDlasGBB0+fmPXdJmjx5clZTK5ziv0or6uczJrS/U+C+Jy5Z\n1f6OGYo6f0mlfQ5FnT+QRKu3G4bdt2hvQYw6f6l4b6Ps9DkUdf7dwFq7WdJmY0zjTV8yxsyW9LKk\nL0naVdIrgdtflrRbJpOsAO+1XaXXeJWeS1BVn1dR0YOyQQ8qj6o+LwCoChaZAQAAOrdI0qvW2t8Y\nY/5N0rclLW+4Ty3zWZVQ8Bctzc5D9W4rk05/gVSm51XF51Ri9CBH6EHleV5VfE4AUEUsMgMAAHTI\nWhs8G/VOSddIul2DOwk9u0t6OMt5AegO9CAAKLd33nnHHwePyAgKXvfuX4bjMh5//PGWtz/00EMZ\nzcQtb96t5h987t18XMaIvCcAAABQFsaYJcaYDw79daqkpyT9StLHjTE7GGPGaPAs1AdymiKACqMH\nAQCAoir+r0IAAAByYIyZLOn7kvaWtMkYc7KkqyTdYox5S9Ibks601q4fetv6f0iqS7rY+wAuAIiL\nHgQAAMqERWYAAIAQ1tpHNbhTsNFWhz5aa2/X4FvWAcAJehAAACgTjssAAAAAAAAAAMTGIjMAAAAA\nAAAAIDYWmQEAAAAAAAAAsXEmcwGcuGRV6PWfz5iQ8UziKfv8pWo8ByCuJUu2OtpRkjRjxoyMZ/L/\nt3f/QXaV5QHHvwvaSmFKRPklVdKm7UNbmDp1KNpAQQyNWJWWwDAVlVQYtVoGcCxrtP5AHWhwLLbA\nVB0ERGQchVLRFqKRaU2jQMSOpq19EFvRAiJqg9HBQPT2j3P2cgm72d2759e99/uZyex7zz25z/Pe\n3X32vu855z3DGfX8YTz6IEmSJEmaXAuaZI6Iw4FPApdk5mUR8Qlg//Lp/YDbgAuBrcCd5fYHM/PU\nivOVNIGsQZIkSZIkSd017yRzROwNXAp8bmbb4MRNRFwJXPHYU3lcxTlKmmDWIEmSJEmSpG5byJnM\nO4AXAdO7PhERASzLzDsiYnnFuY21uZZnWOw+bVlo/r0F7tuGUf8eTBBrUA3mWp5hsfu0ZTH5d7Uf\no/49kCRJkiRpxryTzJm5E9hZzOU8wTkUZxjOOCgirgeeAVyemR/d3Wtv3boVgF6vt9B8K2Vc4xq3\n++qsQZIkSZIkNeVlL3vZUPuPwsknN99884L3vfXWW/vt448/vo50lmQwv4UY7PtZZ51VdTojY+gb\n/0XEzwFHZ+bryk3fB94KXAvsC9wREbdm5v1zvcYRRxxBr9djampq2DSGZlzjGreauG2pogZJktqx\nmJtazuzb9cHVYm/UOY79GpU+SeP4c20NGp0+SdK4GnqSGTgWuGPmQWZuB64qH34vIr4EHAY4wSOp\nDtYgSZIkSZKkDthjCf/3SOArMw8i4vkR8ddle2/g2cBdS0tPkuZkDZIkSZIkSeqAec9kjojnAO8F\nlgOPRsQpwMnAwcA3BnbdBJwREV8E9gQuysx7K89Y0kSxBkmSJEmSJHXbQm78dydw3CxPnb3LfjuB\ntZVkJUkla5AkSZIkSVK3LWW5DEmSJEmSJEnShHOSWZIkSZIkSZI0NCeZJUmSJEmSJElDm3dNZkmS\nJEmSJEnVOfHEE/vtAw88sN9+4IEH+u2bb7650ZyqsHbt2lm333TTTc0mUpH99tuv//WlL33prPtc\nffXVDWbUXZ7JLEmSJEmSJEkammcyS5IkqTU33HDD474OWrNmTdPpVGK2vswY1T7B+PZLk80aNDrG\ntV+SNC6cZJYkSZIkSZJqtmLFin77lFNO6beXLVvWb2/btq3fvuuuu5pJrAIzfXvJS14y6/ODy4Ds\nu+++jeQ0rMH8jjrqqP7Xufq2adOmRvLqOpfLkCRJkiRJkiQNzTOZ1YprLnxuJa/zyjffVsnrSJos\nU1NTlbxOr9er5HUkSZIkSRplU20OkKempnq9Xq+ywf5iGLfduHVPMnetv2Mct/mg1XKGcEI5yTw2\nRrkG+cMjjbZRrj9gDZJGnTVIUptmrUEulyFJkiRJkiRJGprLZagVi13moqoznyUJFn8GchtXCkiS\nJEmSNCo8k1mSJEmSJEmSNDQnmSVJkiRJkiRJQ3O5DLXC5S8ktcnlLyRJkiRJqo6TzJIkSZIkSeqL\niMOBTwKXZOZlEfFM4CPAnsD9wCsyc0dEnA6cC/wM+GBmfqi1pCW1yuUyJEmSJEmSBEBE7A1cCnxu\nYPM7gcsz8xjgbuBV5X5vA1YBxwHnRcR+DacrqSM8k1mteOWbb1vU/i6vIalKvV5vUfu7vIYkSZIm\nyA7gRcD0wLbjgNeW7U8BbwQS2JKZDwFExGZgZfm8pAnjJLMkSZIkSZIAyMydwM6IGNy8d2buKNvf\nBQ4GDgIeHNhnZrukCeQksyRJ0hxmWY/wE8D+5dP7AbcBFwJbgTvL7Q9m5qmNJytp7FiDJHXUXJf5\nefmfNMGcZFYrXP5CUptc/kILMdt6hIMTNxFxJXDFY0/lcY0mKGmsWYMkdcyPImKvzHwYOAS4r/x3\n0MA+h1Ac/JI0gbzxnyRJ0uxm1iO8b9cnorh+dFlm3tF4VpImhTVIUpdsBNaU7TXALcDtwJERsSwi\n9qFYj3lTS/lJaplnMkuSJM1ijvUIZ5xDcYbhjIMi4nrgGRR3Xv9oAylKGmPWIEltiYjnAO8FlgOP\nRsQpwOnA1RHxGuAe4MOZ+WhEvAnYAPSAC2ZuAihp8ozsJPMf/ckBnXgN4w4X9++3/ndtr72Q5+o0\naXEn1fT09Pw77cb69euX/BrGHT7u+eefX8nrz9WnrvV3nOO2ISJ+Djg6M19Xbvo+8FbgWmBf4I6I\nuDUz728lQUljzRokqW6ZeSdw3CxPnTDLvtcD19edk8bXD3/4w377/e9//5Jfb8WKFf32mjVrdrOn\nqjayk8ySJEktORboX6KemduBq8qH34uILwGHAU7wSKqDNUiSJHXOSE0yd/VMzW/91i/128/6j/9t\nMRN1yclH/Eq/XdWZ22pXG2dqLsTmzZv77ZUrV7aYibrk4osv7rerOnNbfUcCX5l5EBHPB16SmW8o\nb9T1bOCutpLT6JqamqLX61V2c9Jer1fJ66hzrEGqTZU3R7YGSdJkaXWSeWbSuKuTx5LGX1cnjiW1\nb471CE8GDga+MbDrJuCMiPgisCdwUWbe23C6ksaMNUiSNAl27NjRb3/5y19e8P/bsGFDv71t27Z+\ne9WqVf22y2U0a6TOZJYkSWrKbtYjPHuX/XYCaxtISdIEsQZJkqRRskfbCUiSJEmSJEmSRteCzmSO\niIuBY8r9LwK2AB+huBzrfuAVmbkjIk4HzgV+BnwwMz9US9aSJob1R5I0KWbWL13MOqZVrp8qSYtd\nR9kaJGmp9t9//377Yx/72IL/3wknnNBvb9y4sdKcNJx5z2QubyRxeGY+D3gh8D7gncDlmXkMcDfw\nqvImE28DVlFc1nVeROxXV+KSxp/1R5IkSZIkqfsWslzG54FTy/Y2YG+KSZybym2fopjYOQrYkpkP\nZebDwGZgZaXZSpo01h9JkiRJkqSOm1rM5TAR8WqKy9ZXZ+YB5bYVFJeuXwYcmZnnldvfBXw7Mz84\n1+t969v/1XvWMw9bQvqSWtbY9XFV15/S4q4HlNQZ09PTrF+/fpSv0bX+6Ammpqbo9XqVXX6+2Mve\ntSijXH/AGqQ5VLn8hTWoVtYgjY177rmn316+fPmSX2/VqlX99mc/+9klv55mNWsNWtCazAARcRJw\nJvAHwNfne+HdbO87Z/pYbrzuAf74ZQcuNI3KGNe4xq0mbhPqqD8zpqenl5DZ8NavX99KbOMad5zi\nSpIkSZK6YSHLZRARq4G3ACdm5kPAjyJir/LpQ4D7yn8HDfy3me2SNDTrjyRJkiRJUrfNeyZzROwL\nvAdYlZk/KDdvBNYA15ZfbwFuB66IiGXATor1UM+tI2lJk8H6I0maJDOXli/mEvMqL22XpMUucWEN\nkrRUhx56aL+9mBp0wgkn9NsbN26sNCcNZyHLZZwGPB34eETMbDuDYkLnNcA9wIcz89GIeBOwgWJ9\nnQvKsw4laVjWH0mSJEmSpI6bd5K5vHHWbDfPOmGWfa8Hrq8gL0my/kiSJEmSNMaqvvGf2rOgNZkl\nSZIkSZIkSZrNQpbLkCRJklSzqakper2ea5xKao31R5I0LCeZJUmSJEmS1Blbt24F4NOf/nTLmQxv\n3bp1XHTRRW2nUbul9vORRx7pt88+++wl5/PkJz+5367q/Z+E7+Vi+rhu3bpZt7tchiRJkiRJkiRp\naJ7JLEmS1FHT09O1x1i/fn0jccxhfueff/7jvi7VsP3pwnvRlTzmymH9+vUtZNO8ut//LnyPu5JH\nV3Koqv7AaNegLuSwuzwmpQZJGi1OMkuSJEmSJKkRGzZsYPXq1WzYsOFx27ds2dJvb9++vem0FmXz\n5s399sqVK+fcb9u2bU2k07qq+rnXXntV8jozqnz/6/5eXnzxxf12lQf8FmOpfXSSWZIkqUO6cObU\nQix0cCUtxODACtobXMkapMm0aw3yTGFJWjwnmSVJkho2PT3dmUtxJU0ea5AkSapaq5PMN173wFT5\nta34xjWucSfbVJtnKbQV27jGHae4kiRJGi2rV6+eKr/uur2VfOo0KZ+RJ6GfdfexC+/hUnOY6vV6\nFaUiSZIkSZIkSZo0e7SdgCRJkiRJkiRpdDnJLEmSJEmSJEkampPMkiRJkiRJkqShOcksSZIkSZIk\nSRqak8ySJEmSJEmSpKE5ySxJkiRJkiRJGtqT2gocEZcAzwV6wDmZuaXmeBcDx1D0+SJgC/ARYE/g\nfuAVmbmjpth7Af8OvAv4XBNxI+J04HxgJ/A24Kt1x42IfYBrgKcCPw9cAHwH+DuK7/NXM/PPKox3\nOPBJ4JLMvCwinsksfSzfi3OBnwEfzMwP1RT7KuDJwKPAyzPzO1XH3jXuwPbVwC2ZOVU+rrzP46bJ\nGjRp9aeMaw2qqQZZfyRJkjTKmp4Pakqb474mtTXGbFIb49km1TV2bmWSOSKOBX4tM58XEb8BXAk8\nr8Z4zwcOL+M9Dfg3il+EyzPzExFxIfAqijezDn8J/KBsv7PuuGUf3w48B9iH4ofllLrjAmuBzMx1\nEfEM4FaKX75zMnNLRFwXESdm5s1LDRQRewOXUnwfZzzhvY2IaygKwu8CjwBbIuLGzPzBE150abHf\nTTGZ8vGIeD3whoi4oMrYc8QlIp4CrKN4r2f2q7TP46bJGjRp9QesQXXWIOvP+GhrcNWlwU/bA5Qu\nDB6aPji2S+zWDtYvII/aD5ztLoeB7WN5EK3NyZ2u1KC260+ZQ6s1qM36U8a3Bs2Rw8D2ca1Bjc4H\nNaUD474mNT7GbFKL49kmraWGsXNby2W8APgHgMz8GvDUiPjFGuN9Hji1bG8D9gaOA24qt30KWFVH\n4Ig4DPhN4B/LTU3EXQVszMztmXl/Zr66objfA55Wtp9KUXR+eeCDa5VxdwAvAu4b2HYcT+zjUcCW\nzHwoMx8GNgMra4j9OuCGsv0gxftQdezZ4gK8GbicYkKHGuKOoyZr0KTVH7AGDcZqog5Yf0bM4OAK\nOBP424bi9gc/wAuB9/HYwOAY4G6KD8xNmW2A0kgeA4OHo4EXAyc1nUNpLcUH/OdTDF7+huL7ck5m\nrgT2jYgTqw46z4Gyfv8HDhytoqhx50XEfjXnMXPg7FjgRooDZ7XlMcRBtFrei6a0VX/K2F2qQa3V\nH+hMDVpLC/UHrEELyGFsa1Cp6fmgprQ27mtSi2PMJrU1nm1SLWPntiaZD6IYCM94sNxWi8z8aWb+\nuHx4JvBPwN4DR4a/CxxcU/j3Am8YeNxE3OXAL0TETRGxKSJe0ETczPwY8KyIuJuiwL4R+L+BXSqL\nm5k7ywmMQbP1cdeftSXnMFvszPxxZv40IvYEXg9cV3Xs2eJGxK8Dv52ZnxjYXHmfx1BjNWgC6w9Y\ngwZj1V4HrD8jqa3BVWcGPx0YoHRl8NDkwbFBbR6sny+PJg6czZcDjO9BtDYndzpRgzpQf6AbNait\n+gPWoPlygPGtQdDwfFBTWh73NamtMWaTltPCeLZJdY2du3Ljv6kmgkTESRS/7H/eRPyIeCXwxcz8\nnzl2qavfUxR/DE+mOEJ91S6x6urvy4FvZeavAscD186SV1PmilVbDuUEz0eAWzPzc7PsUkfsS3h8\ngZ9Nk+/7qKr9PZqg+jPz2tagxW1fEuvPyGllcNWxwU/bA5TldGDw0OTBsV3itnawfr48mjhwNl8O\nY34QrbXJnQ7VoLbrD3SgBrVVf8rY1qDd5DDmNWg2Y/V5selxX5NaHmM2qZXxbJPqGju3Ncl8H4//\nMPMMystA6lKuZ/QW4MTMfAj4UbkWF8AhPPHIYRX+EDgpIm4DzgLe2lDcB4AvlH+wvgFsB7Y3EHcl\nsAEgM78C7AU8feD5uuLOmO293fVnrc4crgK+npkXlI9rjR0RhwCHAR8tf8YOjoh/qTvumGi0Bk1Y\n/QFr0GCspn4frT+jrdEPqm0PfjoyQOnE4KFjB8cWErep96WNA2eDJukgWuP9aLMGdaT+zMRptQZ1\nuP7sLrY1qLkc6tT4fFBTWhr3NanNMWaT2hrPNqmWsXNbk8yfoVj3iYj4HeC+zNxeV7CI2Bd4D/Di\nfOzmQxuBNWV7DXBL1XEz87TMPDIznwtcQXFjidrjUry/x0fEHuV6X/s0FPduist4iIhDKX4RvxYR\nR5fPn1xT3Bmz9fF24MiIWBbFzS1WApuqDlzehOGRzHz7wOZaY2fmvZm5IjOfW/6M3Z/F2mGN9HnE\nNVaDJrD+gDUIGqxB1p+R1NrgqiODny4MULoyeGj74Nigtg/WD2r0wNmgCTiI1urkTgdqUBfqD3Sj\nBnWp/oA1CJiIGgQNzwc1pa1xX5NaHmM2qa3xbJNqGTs/qbL0FiEzvxARd0bEFyjujPr6mkOeRvEH\n8+MRMbPtDOCKiHgNcA/w4ZpzmPF24Jo642bmvRFxPXBbuelsijs31xoX+ABwZflH8EnAaynuUPyB\niNgDuD0zN1YRKCKeQ3Gp23Lg0Yg4BTgduHqwj5n5aES8ieIDVA+4oPxAW3XsA4CfRMQ/l7v9Z2a+\nrsrYc8Q9eeAPGACZ+XDVfR43Ddegiao/YA2qswZZf8bGZyjuUv2BJgdXA4OfVbMMfq6loQ/MmXna\nQE7vAL4J/F7DeXyG4vd1PcVapPtQ/Nw2+l7w2Af8GwY+4H8zIo7OzH+l+IB/aQN5wOw/C7dT/L1a\nBuykmJQ6t84kdnPgrJE8MvNeYMVAPt/MzGPLya9G34uatFJ/oBs1qCP1B7pRg7pUf8AaBExEDWpj\nPqgpXRr3NamRMWaTWhzPNqmWsfNUr9erNk1JkiTtVkT8FfD7lIOr8iyyumO+GngHcNfA5jMozkR5\nCsUH5j/NzEfrzmUgp3dQTPJsAK5pMo9ykHBm+fDdlIOHhnPYB7gSOJDiA/5bKT/gU1xxeHtmznfJ\n9DBxH3fgCLiX8kAZu/S/PKj0FxQHji7NzI/WnMcBwE+AH5a7zRw4qyWPOXLoH0QrJ3iWl+3a3osm\ntVF/yridqkFt1p8yfqs1qK36U8a2Bu0+h7GuQZLGl5PMkiRJkiRJkqShtbUmsyRJkiRJkiRpDDjJ\nLEmSJEmSJEkampPMkiRJkiRJkqShOcksSZIkSZIkSRqak8ySJEmSJEmSpKE5ySxJkiRJkiRJGpqT\nzJIkSZIkSZKkQZHRDgAAAAdJREFUof0/uswKQTO5fjgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f49d6a2a898>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Running: Episode: 0 Total reward: 120.0 Explore P: 0.9951 nTraining RunningLoss 847.6860 Loss 1.6954 Time Lapse 0.3394514600435893 Min. Step: 500 Exploration Action 4\n",
            "Done: Episode: 0 Total reward: 195.0 Explore P: 0.9912 nTraining RunningLoss 646.9156 Loss 0.0129 Time Lapse 0.5941988110542298 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 0 Total reward: 195.0 Explore P: 0.9912 nTraining RunningLoss 646.3816 Loss 1.2928 Time Lapse 0.5949719031651814 Min. Step: 50000 Exploration Action 0\n",
            "Saving Model and Updating Target\n",
            "Running: Episode: 1 Total reward: 50.0 Explore P: 0.9863 nTraining RunningLoss 278.7762 Loss 0.5576 Time Lapse 0.9218075116475423 Min. Step: 500 Exploration Action 1\n",
            "Done: Episode: 1 Total reward: 110.0 Explore P: 0.9847 nTraining RunningLoss 235.8268 Loss 0.0047 Time Lapse 1.0287882367769876 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 1 Total reward: 110.0 Explore P: 0.9847 nTraining RunningLoss 235.5268 Loss 0.4711 Time Lapse 1.0294092496236165 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 2 Total reward: 105.0 Explore P: 0.9798 nTraining RunningLoss 146.6598 Loss 0.2933 Time Lapse 1.354206387201945 Min. Step: 500 Exploration Action 3\n",
            "Done: Episode: 2 Total reward: 160.0 Explore P: 0.9762 nTraining RunningLoss 95.1341 Loss 0.0019 Time Lapse 1.5957912047704061 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 2 Total reward: 160.0 Explore P: 0.9762 nTraining RunningLoss 94.9332 Loss 0.1899 Time Lapse 1.5964904030164082 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 3 Total reward: 80.0 Explore P: 0.9714 nTraining RunningLoss 152459.6250 Loss 304.9192 Time Lapse 1.9192381938298544 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 3 Total reward: 80.0 Explore P: 0.9713 nTraining RunningLoss 49.4866 Loss 0.0010 Time Lapse 1.9240246017773945 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 3 Total reward: 80.0 Explore P: 0.9713 nTraining RunningLoss 49.4830 Loss 0.0990 Time Lapse 1.924678381284078 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 4 Total reward: 75.0 Explore P: 0.9665 nTraining RunningLoss 30.6324 Loss 0.0613 Time Lapse 2.2448896686236064 Min. Step: 500 Exploration Action 1\n",
            "Done: Episode: 4 Total reward: 95.0 Explore P: 0.9646 nTraining RunningLoss 31.5254 Loss 0.0006 Time Lapse 2.3770284692446393 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 4 Total reward: 95.0 Explore P: 0.9646 nTraining RunningLoss 31.5772 Loss 0.0632 Time Lapse 2.3776926000912986 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 5 Total reward: 105.0 Explore P: 0.9599 nTraining RunningLoss 442.0328 Loss 0.8841 Time Lapse 2.699917503197988 Min. Step: 500 Exploration Action 3\n",
            "Done: Episode: 5 Total reward: 210.0 Explore P: 0.9568 nTraining RunningLoss 173.3270 Loss 0.0035 Time Lapse 2.903378947575887 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 5 Total reward: 210.0 Explore P: 0.9568 nTraining RunningLoss 103.9151 Loss 0.2078 Time Lapse 2.904048204421997 Min. Step: 50000 Exploration Action 1\n",
            "Done: Episode: 6 Total reward: 110.0 Explore P: 0.9523 nTraining RunningLoss 1928.5040 Loss 0.0386 Time Lapse 3.2094372312227883 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 6 Total reward: 110.0 Explore P: 0.9523 nTraining RunningLoss 32500.2480 Loss 65.0005 Time Lapse 3.2101128061612445 Min. Step: 50000 Exploration Action 1\n",
            "Done: Episode: 7 Total reward: 135.0 Explore P: 0.9477 nTraining RunningLoss 215.6778 Loss 0.0043 Time Lapse 3.5272265553474424 Min. Step: 50000 Exploration Action 5\n",
            "Running: Episode: 7 Total reward: 135.0 Explore P: 0.9477 nTraining RunningLoss 215.8216 Loss 0.4316 Time Lapse 3.527876687049866 Min. Step: 50000 Exploration Action 5\n",
            "Running: Episode: 8 Total reward: 90.0 Explore P: 0.9430 nTraining RunningLoss 395.5505 Loss 0.7911 Time Lapse 3.844142508506775 Min. Step: 500 Exploration Action 3\n",
            "Done: Episode: 8 Total reward: 210.0 Explore P: 0.9405 nTraining RunningLoss 189.1943 Loss 0.0038 Time Lapse 4.010242835680644 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 8 Total reward: 210.0 Explore P: 0.9405 nTraining RunningLoss 188.4758 Loss 0.3770 Time Lapse 4.010878562927246 Min. Step: 50000 Exploration Action 1\n",
            "Done: Episode: 9 Total reward: 120.0 Explore P: 0.9363 nTraining RunningLoss 78996.9844 Loss 1.5799 Time Lapse 4.29192271232605 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 9 Total reward: 120.0 Explore P: 0.9363 nTraining RunningLoss 679.6283 Loss 1.3593 Time Lapse 4.292606417338053 Min. Step: 50000 Exploration Action 4\n",
            "Done: Episode: 10 Total reward: 70.0 Explore P: 0.9326 nTraining RunningLoss 649.9005 Loss 0.0130 Time Lapse 4.544851052761078 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 10 Total reward: 70.0 Explore P: 0.9326 nTraining RunningLoss 657.0801 Loss 1.3142 Time Lapse 4.545524072647095 Min. Step: 50000 Exploration Action 0\n",
            "Saving Model and Updating Target\n",
            "Running: Episode: 11 Total reward: 110.0 Explore P: 0.9280 nTraining RunningLoss 0.1726 Loss 0.0003 Time Lapse 4.864164992173513 Min. Step: 500 Exploration Action 0\n",
            "Done: Episode: 11 Total reward: 110.0 Explore P: 0.9266 nTraining RunningLoss 0.1413 Loss 0.0000 Time Lapse 4.966868261496226 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 11 Total reward: 110.0 Explore P: 0.9266 nTraining RunningLoss 97.6670 Loss 0.1953 Time Lapse 4.967517797152201 Min. Step: 50000 Exploration Action 1\n",
            "Done: Episode: 12 Total reward: 120.0 Explore P: 0.9228 nTraining RunningLoss 23.6260 Loss 0.0005 Time Lapse 5.224667839209238 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 12 Total reward: 120.0 Explore P: 0.9228 nTraining RunningLoss 0.2637 Loss 0.0005 Time Lapse 5.225334266821544 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 13 Total reward: 80.0 Explore P: 0.9182 nTraining RunningLoss 0.6359 Loss 0.0013 Time Lapse 5.554675130049388 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 13 Total reward: 80.0 Explore P: 0.9181 nTraining RunningLoss 0.4216 Loss 0.0000 Time Lapse 5.563565715154012 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 13 Total reward: 80.0 Explore P: 0.9181 nTraining RunningLoss 0.4026 Loss 0.0008 Time Lapse 5.5642617583274845 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 14 Total reward: 80.0 Explore P: 0.9136 nTraining RunningLoss 0.7803 Loss 0.0016 Time Lapse 5.895079040527344 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 14 Total reward: 120.0 Explore P: 0.9123 nTraining RunningLoss 0.1367 Loss 0.0000 Time Lapse 5.994973448912303 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 14 Total reward: 120.0 Explore P: 0.9123 nTraining RunningLoss 0.1415 Loss 0.0003 Time Lapse 5.99565106232961 Min. Step: 50000 Exploration Action 3\n",
            "Done: Episode: 15 Total reward: 100.0 Explore P: 0.9079 nTraining RunningLoss 1.1420 Loss 0.0000 Time Lapse 6.320067628224691 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 15 Total reward: 100.0 Explore P: 0.9079 nTraining RunningLoss 1.0767 Loss 0.0022 Time Lapse 6.320709228515625 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 16 Total reward: 60.0 Explore P: 0.9034 nTraining RunningLoss 0.3743 Loss 0.0007 Time Lapse 6.644136015574137 Min. Step: 500 Exploration Action 2\n",
            "Done: Episode: 16 Total reward: 105.0 Explore P: 0.9021 nTraining RunningLoss 0.2557 Loss 0.0000 Time Lapse 6.74557501077652 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 16 Total reward: 105.0 Explore P: 0.9021 nTraining RunningLoss 0.2150 Loss 0.0004 Time Lapse 6.746268836657206 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 17 Total reward: 55.0 Explore P: 0.8976 nTraining RunningLoss 0.0229 Loss 0.0000 Time Lapse 7.079814624786377 Min. Step: 500 Exploration Action 5\n",
            "Running: Episode: 17 Total reward: 425.0 Explore P: 0.8932 nTraining RunningLoss 70.6413 Loss 0.1413 Time Lapse 7.399731945991516 Min. Step: 1000 Explotation Action 0\n",
            "Running: Episode: 17 Total reward: 425.0 Explore P: 0.8888 nTraining RunningLoss 15538.7803 Loss 31.0776 Time Lapse 7.750867791970571 Min. Step: 1500 Exploration Action 0\n",
            "Done: Episode: 17 Total reward: 425.0 Explore P: 0.8886 nTraining RunningLoss 15902.4326 Loss 0.3180 Time Lapse 7.761687326431274 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 17 Total reward: 425.0 Explore P: 0.8886 nTraining RunningLoss 15914.4336 Loss 31.8289 Time Lapse 7.762317490577698 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 18 Total reward: 35.0 Explore P: 0.8843 nTraining RunningLoss 37654.6094 Loss 75.3092 Time Lapse 8.081199983755747 Min. Step: 500 Exploration Action 0\n",
            "Done: Episode: 18 Total reward: 140.0 Explore P: 0.8820 nTraining RunningLoss 52957.5195 Loss 1.0592 Time Lapse 8.246654415130616 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 18 Total reward: 140.0 Explore P: 0.8820 nTraining RunningLoss 53142.1328 Loss 106.2843 Time Lapse 8.247325905164082 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 19 Total reward: 155.0 Explore P: 0.8776 nTraining RunningLoss 102015.3359 Loss 204.0307 Time Lapse 8.578968691825867 Min. Step: 500 Exploration Action 3\n",
            "Running: Episode: 19 Total reward: 300.0 Explore P: 0.8733 nTraining RunningLoss 163756.8750 Loss 327.5138 Time Lapse 8.894916745026906 Min. Step: 1000 Explotation Action 0\n",
            "Done: Episode: 19 Total reward: 300.0 Explore P: 0.8731 nTraining RunningLoss 166763.7656 Loss 3.3353 Time Lapse 8.907202315330505 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 19 Total reward: 300.0 Explore P: 0.8731 nTraining RunningLoss 166976.0781 Loss 333.9522 Time Lapse 8.907834927241007 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 20 Total reward: 45.0 Explore P: 0.8688 nTraining RunningLoss 303259.9062 Loss 606.5198 Time Lapse 9.255139474074046 Min. Step: 500 Exploration Action 4\n",
            "Done: Episode: 20 Total reward: 45.0 Explore P: 0.8687 nTraining RunningLoss 3941605888.0000 Loss 78832.1178 Time Lapse 9.263551247119903 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 20 Total reward: 45.0 Explore P: 0.8687 nTraining RunningLoss 304707.3125 Loss 609.4146 Time Lapse 9.264216220378875 Min. Step: 50000 Exploration Action 0\n",
            "Saving Model and Updating Target\n",
            "Running: Episode: 21 Total reward: 50.0 Explore P: 0.8644 nTraining RunningLoss 21377.3691 Loss 42.7547 Time Lapse 9.611914547284444 Min. Step: 500 Exploration Action 0\n",
            "Done: Episode: 21 Total reward: 120.0 Explore P: 0.8615 nTraining RunningLoss 18530.7656 Loss 0.3706 Time Lapse 9.839064971605938 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 21 Total reward: 120.0 Explore P: 0.8615 nTraining RunningLoss 18521.9062 Loss 37.0438 Time Lapse 9.839697444438935 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 22 Total reward: 105.0 Explore P: 0.8573 nTraining RunningLoss 14120.9365 Loss 28.2419 Time Lapse 10.161845604578653 Min. Step: 500 Exploration Action 5\n",
            "Running: Episode: 22 Total reward: 195.0 Explore P: 0.8531 nTraining RunningLoss 9831.7441 Loss 19.6635 Time Lapse 10.53190422852834 Min. Step: 1000 Exploration Action 4\n",
            "Done: Episode: 22 Total reward: 195.0 Explore P: 0.8525 nTraining RunningLoss 9493.1914 Loss 0.1899 Time Lapse 10.586111160119374 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 22 Total reward: 195.0 Explore P: 0.8525 nTraining RunningLoss 36456.3867 Loss 72.9128 Time Lapse 10.586907200018565 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 23 Total reward: 70.0 Explore P: 0.8483 nTraining RunningLoss 5931.1934 Loss 11.8624 Time Lapse 11.006192700068157 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 23 Total reward: 160.0 Explore P: 0.8460 nTraining RunningLoss 4468.1919 Loss 0.0894 Time Lapse 11.229015111923218 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 23 Total reward: 160.0 Explore P: 0.8460 nTraining RunningLoss 4462.9141 Loss 8.9258 Time Lapse 11.229738521575928 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 24 Total reward: 135.0 Explore P: 0.8419 nTraining RunningLoss 2308.2476 Loss 4.6165 Time Lapse 11.619847269852956 Min. Step: 500 Exploration Action 5\n",
            "Running: Episode: 24 Total reward: 165.0 Explore P: 0.8377 nTraining RunningLoss 1008.2086 Loss 2.0164 Time Lapse 11.986920277277628 Min. Step: 1000 Exploration Action 3\n",
            "Done: Episode: 24 Total reward: 210.0 Explore P: 0.8369 nTraining RunningLoss 842.6740 Loss 0.0169 Time Lapse 12.055377976099651 Min. Step: 50000 Exploration Action 5\n",
            "Running: Episode: 24 Total reward: 210.0 Explore P: 0.8369 nTraining RunningLoss 841.1049 Loss 1.6822 Time Lapse 12.056095532576244 Min. Step: 50000 Exploration Action 5\n",
            "Done: Episode: 25 Total reward: 50.0 Explore P: 0.8334 nTraining RunningLoss 349.2455 Loss 0.0070 Time Lapse 12.34272647301356 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 25 Total reward: 50.0 Explore P: 0.8334 nTraining RunningLoss 348.3742 Loss 0.6967 Time Lapse 12.343394823869069 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 26 Total reward: 105.0 Explore P: 0.8293 nTraining RunningLoss 97.7945 Loss 0.1956 Time Lapse 12.681661891937257 Min. Step: 500 Exploration Action 0\n",
            "Done: Episode: 26 Total reward: 135.0 Explore P: 0.8270 nTraining RunningLoss 42.8375 Loss 0.0009 Time Lapse 12.873873090744018 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 26 Total reward: 135.0 Explore P: 0.8270 nTraining RunningLoss 42.7158 Loss 0.0854 Time Lapse 12.874595816930135 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 27 Total reward: 185.0 Explore P: 0.8229 nTraining RunningLoss 7.0947 Loss 0.0142 Time Lapse 13.31797587076823 Min. Step: 500 Exploration Action 4\n",
            "Done: Episode: 27 Total reward: 215.0 Explore P: 0.8203 nTraining RunningLoss 2.5041 Loss 0.0001 Time Lapse 13.919452083110809 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 27 Total reward: 215.0 Explore P: 0.8203 nTraining RunningLoss 2.4969 Loss 0.0050 Time Lapse 13.92119266986847 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 28 Total reward: 120.0 Explore P: 0.8162 nTraining RunningLoss 0.0553 Loss 0.0001 Time Lapse 14.820162836710612 Min. Step: 500 Exploration Action 3\n",
            "Done: Episode: 28 Total reward: 210.0 Explore P: 0.8147 nTraining RunningLoss 224.3159 Loss 0.0045 Time Lapse 15.160531640052795 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 28 Total reward: 210.0 Explore P: 0.8147 nTraining RunningLoss 23378.3574 Loss 46.7567 Time Lapse 15.161848413944245 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 29 Total reward: 120.0 Explore P: 0.8107 nTraining RunningLoss 0.0014 Loss 0.0000 Time Lapse 16.050604291756947 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 29 Total reward: 285.0 Explore P: 0.8075 nTraining RunningLoss 0.0795 Loss 0.0000 Time Lapse 16.733535035451254 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 29 Total reward: 285.0 Explore P: 0.8075 nTraining RunningLoss 51.9135 Loss 0.1038 Time Lapse 16.734980376561484 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 30 Total reward: 105.0 Explore P: 0.8035 nTraining RunningLoss 0.0066 Loss 0.0000 Time Lapse 17.577531123161314 Min. Step: 500 Exploration Action 3\n",
            "Done: Episode: 30 Total reward: 105.0 Explore P: 0.8033 nTraining RunningLoss 0.0003 Loss 0.0000 Time Lapse 17.630727525552114 Min. Step: 50000 Exploration Action 5\n",
            "Running: Episode: 30 Total reward: 105.0 Explore P: 0.8033 nTraining RunningLoss 0.0003 Loss 0.0000 Time Lapse 17.63212585846583 Min. Step: 50000 Exploration Action 5\n",
            "Saving Model and Updating Target\n",
            "Running: Episode: 31 Total reward: 125.0 Explore P: 0.7993 nTraining RunningLoss 3.1104 Loss 0.0062 Time Lapse 18.466364693641662 Min. Step: 500 Exploration Action 0\n",
            "Done: Episode: 31 Total reward: 180.0 Explore P: 0.7983 nTraining RunningLoss 1.1479 Loss 0.0000 Time Lapse 18.664724938074748 Min. Step: 50000 Exploration Action 5\n",
            "Running: Episode: 31 Total reward: 180.0 Explore P: 0.7983 nTraining RunningLoss 19023.3203 Loss 38.0466 Time Lapse 18.666022408008576 Min. Step: 50000 Exploration Action 5\n",
            "Running: Episode: 32 Total reward: 50.0 Explore P: 0.7944 nTraining RunningLoss 0.0876 Loss 0.0002 Time Lapse 19.44933930238088 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 32 Total reward: 125.0 Explore P: 0.7928 nTraining RunningLoss 393.2087 Loss 0.0079 Time Lapse 19.750053290526072 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 32 Total reward: 125.0 Explore P: 0.7928 nTraining RunningLoss 0.3281 Loss 0.0007 Time Lapse 19.75130749940872 Min. Step: 50000 Explotation Action 0\n",
            "Done: Episode: 33 Total reward: 5.0 Explore P: 0.7890 nTraining RunningLoss 0.1609 Loss 0.0000 Time Lapse 20.502557297547657 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 33 Total reward: 5.0 Explore P: 0.7890 nTraining RunningLoss 0.1652 Loss 0.0003 Time Lapse 20.50383921464284 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 34 Total reward: 110.0 Explore P: 0.7851 nTraining RunningLoss 0.0948 Loss 0.0002 Time Lapse 21.29458094437917 Min. Step: 500 Exploration Action 3\n",
            "Done: Episode: 34 Total reward: 135.0 Explore P: 0.7830 nTraining RunningLoss 0.3344 Loss 0.0000 Time Lapse 21.698337133725484 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 34 Total reward: 135.0 Explore P: 0.7830 nTraining RunningLoss 0.3225 Loss 0.0006 Time Lapse 21.699530998865765 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 35 Total reward: 125.0 Explore P: 0.7791 nTraining RunningLoss 0.0485 Loss 0.0001 Time Lapse 22.415228589375815 Min. Step: 500 Explotation Action 0\n",
            "Done: Episode: 35 Total reward: 180.0 Explore P: 0.7782 nTraining RunningLoss 0.6488 Loss 0.0000 Time Lapse 22.5776038646698 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 35 Total reward: 180.0 Explore P: 0.7782 nTraining RunningLoss 0.6421 Loss 0.0013 Time Lapse 22.578731365998586 Min. Step: 50000 Exploration Action 4\n",
            "Done: Episode: 36 Total reward: 80.0 Explore P: 0.7751 nTraining RunningLoss 0.3935 Loss 0.0000 Time Lapse 23.13180522521337 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 36 Total reward: 80.0 Explore P: 0.7751 nTraining RunningLoss 0.4225 Loss 0.0008 Time Lapse 23.13295772075653 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 37 Total reward: 50.0 Explore P: 0.7713 nTraining RunningLoss 0.0047 Loss 0.0000 Time Lapse 23.78329917192459 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 37 Total reward: 105.0 Explore P: 0.7704 nTraining RunningLoss 0.2725 Loss 0.0000 Time Lapse 23.94957511027654 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 37 Total reward: 105.0 Explore P: 0.7704 nTraining RunningLoss 0.2998 Loss 0.0006 Time Lapse 23.950693424542745 Min. Step: 50000 Exploration Action 3\n",
            "Running: Episode: 38 Total reward: 55.0 Explore P: 0.7666 nTraining RunningLoss 3.4950 Loss 0.0070 Time Lapse 24.612142634391784 Min. Step: 500 Exploration Action 0\n",
            "Done: Episode: 38 Total reward: 85.0 Explore P: 0.7660 nTraining RunningLoss 8.8544 Loss 0.0002 Time Lapse 24.71518644889196 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 38 Total reward: 85.0 Explore P: 0.7660 nTraining RunningLoss 10.0446 Loss 0.0201 Time Lapse 24.71635284423828 Min. Step: 50000 Exploration Action 0\n",
            "Running: Episode: 39 Total reward: 60.0 Explore P: 0.7622 nTraining RunningLoss 0.0473 Loss 0.0001 Time Lapse 25.359738222757976 Min. Step: 500 Exploration Action 2\n",
            "Done: Episode: 39 Total reward: 140.0 Explore P: 0.7591 nTraining RunningLoss 0.3415 Loss 0.0000 Time Lapse 25.893923568725587 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 39 Total reward: 140.0 Explore P: 0.7591 nTraining RunningLoss 0.2804 Loss 0.0006 Time Lapse 25.895022741953532 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 40 Total reward: 0.0 Explore P: 0.7554 nTraining RunningLoss 5.7678 Loss 0.0115 Time Lapse 26.477167769273123 Min. Step: 500 Exploration Action 1\n",
            "Done: Episode: 40 Total reward: 40.0 Explore P: 0.7545 nTraining RunningLoss 0.4829 Loss 0.0000 Time Lapse 26.6006400346756 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 40 Total reward: 40.0 Explore P: 0.7545 nTraining RunningLoss 0.4120 Loss 0.0008 Time Lapse 26.60157284339269 Min. Step: 50000 Exploration Action 1\n",
            "Saving Model and Updating Target\n",
            "Running: Episode: 41 Total reward: 110.0 Explore P: 0.7508 nTraining RunningLoss 0.0248 Loss 0.0000 Time Lapse 27.159294601281484 Min. Step: 500 Exploration Action 1\n",
            "Done: Episode: 41 Total reward: 275.0 Explore P: 0.7479 nTraining RunningLoss 3.1849 Loss 0.0001 Time Lapse 27.596659004688263 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 41 Total reward: 275.0 Explore P: 0.7479 nTraining RunningLoss 92.5903 Loss 0.1852 Time Lapse 27.597642985979714 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 42 Total reward: 110.0 Explore P: 0.7442 nTraining RunningLoss 7.8910 Loss 0.0158 Time Lapse 28.13061178525289 Min. Step: 500 Explotation Action 0\n",
            "Done: Episode: 42 Total reward: 300.0 Explore P: 0.7406 nTraining RunningLoss 99.2763 Loss 0.0020 Time Lapse 28.609813944498697 Min. Step: 50000 Exploration Action 5\n",
            "Running: Episode: 42 Total reward: 300.0 Explore P: 0.7406 nTraining RunningLoss 0.0007 Loss 0.0000 Time Lapse 28.610635101795197 Min. Step: 50000 Exploration Action 5\n",
            "Running: Episode: 43 Total reward: 135.0 Explore P: 0.7370 nTraining RunningLoss 2.9910 Loss 0.0060 Time Lapse 29.08244973818461 Min. Step: 500 Explotation Action 0\n",
            "Done: Episode: 43 Total reward: 155.0 Explore P: 0.7360 nTraining RunningLoss 4.3668 Loss 0.0001 Time Lapse 29.212728420893352 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 43 Total reward: 155.0 Explore P: 0.7360 nTraining RunningLoss 5.9254 Loss 0.0119 Time Lapse 29.213667209943136 Min. Step: 50000 Exploration Action 4\n",
            "Running: Episode: 44 Total reward: 65.0 Explore P: 0.7324 nTraining RunningLoss 0.0011 Loss 0.0000 Time Lapse 29.674785172939302 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 44 Total reward: 135.0 Explore P: 0.7311 nTraining RunningLoss 3.4088 Loss 0.0001 Time Lapse 29.831236155827842 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 44 Total reward: 135.0 Explore P: 0.7311 nTraining RunningLoss 4.4707 Loss 0.0089 Time Lapse 29.832012343406678 Min. Step: 50000 Exploration Action 2\n",
            "Done: Episode: 45 Total reward: 80.0 Explore P: 0.7283 nTraining RunningLoss 15425.8555 Loss 0.3085 Time Lapse 30.149232590198515 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 45 Total reward: 80.0 Explore P: 0.7283 nTraining RunningLoss 0.7291 Loss 0.0015 Time Lapse 30.150035119056703 Min. Step: 50000 Exploration Action 1\n",
            "Running: Episode: 46 Total reward: 110.0 Explore P: 0.7247 nTraining RunningLoss 5.5781 Loss 0.0112 Time Lapse 30.5441996216774 Min. Step: 500 Exploration Action 3\n",
            "Running: Episode: 46 Total reward: 290.0 Explore P: 0.7211 nTraining RunningLoss 2.0507 Loss 0.0041 Time Lapse 30.90585811138153 Min. Step: 1000 Exploration Action 2\n",
            "Done: Episode: 46 Total reward: 290.0 Explore P: 0.7205 nTraining RunningLoss 3.5481 Loss 0.0001 Time Lapse 30.97009805838267 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 46 Total reward: 290.0 Explore P: 0.7205 nTraining RunningLoss 3.9204 Loss 0.0078 Time Lapse 30.97083324988683 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 47 Total reward: 135.0 Explore P: 0.7169 nTraining RunningLoss 15.6475 Loss 0.0313 Time Lapse 31.31984648704529 Min. Step: 500 Exploration Action 4\n",
            "Done: Episode: 47 Total reward: 180.0 Explore P: 0.7151 nTraining RunningLoss 407.1867 Loss 0.0081 Time Lapse 31.489419921239218 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 47 Total reward: 180.0 Explore P: 0.7151 nTraining RunningLoss 0.0130 Loss 0.0000 Time Lapse 31.490137894948322 Min. Step: 50000 Exploration Action 2\n",
            "Running: Episode: 48 Total reward: 50.0 Explore P: 0.7116 nTraining RunningLoss 26.1096 Loss 0.0522 Time Lapse 31.803553982575735 Min. Step: 500 Exploration Action 5\n",
            "Done: Episode: 48 Total reward: 105.0 Explore P: 0.7107 nTraining RunningLoss 0.0317 Loss 0.0000 Time Lapse 31.886537607510885 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 48 Total reward: 105.0 Explore P: 0.7107 nTraining RunningLoss 0.0006 Loss 0.0000 Time Lapse 31.887171161174773 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 49 Total reward: 120.0 Explore P: 0.7072 nTraining RunningLoss 0.1038 Loss 0.0002 Time Lapse 32.21335774262746 Min. Step: 500 Explotation Action 0\n",
            "Done: Episode: 49 Total reward: 210.0 Explore P: 0.7047 nTraining RunningLoss 0.0961 Loss 0.0000 Time Lapse 32.44001998504003 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 49 Total reward: 210.0 Explore P: 0.7047 nTraining RunningLoss 0.0996 Loss 0.0002 Time Lapse 32.44065517584483 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 50 Total reward: 40.0 Explore P: 0.7013 nTraining RunningLoss 0.0101 Loss 0.0000 Time Lapse 32.778142841657 Min. Step: 500 Explotation Action 0\n",
            "Done: Episode: 50 Total reward: 55.0 Explore P: 0.7001 nTraining RunningLoss 2.2383 Loss 0.0000 Time Lapse 32.910416678587595 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 50 Total reward: 55.0 Explore P: 0.7001 nTraining RunningLoss 3.0276 Loss 0.0061 Time Lapse 32.91112941503525 Min. Step: 50000 Explotation Action 0\n",
            "Saving Model and Updating Target\n",
            "Running: Episode: 51 Total reward: 35.0 Explore P: 0.6967 nTraining RunningLoss 90.5903 Loss 0.1812 Time Lapse 33.24481851259868 Min. Step: 500 Exploration Action 2\n",
            "Done: Episode: 51 Total reward: 180.0 Explore P: 0.6950 nTraining RunningLoss 0.2071 Loss 0.0000 Time Lapse 33.406445451577504 Min. Step: 50000 Explotation Action 0\n",
            "Running: Episode: 51 Total reward: 180.0 Explore P: 0.6950 nTraining RunningLoss 1.5782 Loss 0.0032 Time Lapse 33.40711749792099 Min. Step: 50000 Explotation Action 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}